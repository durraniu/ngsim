[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Importing, Transforming, Analyzing, and Visualizing NGSIM Data",
    "section": "",
    "text": "This page contains several posts that show how to import, transform, analyze and visualize NGSIM vehicle trajectory data using programming tools (mostly R, but sometimes Python and Julia).\nFrom the Next Generation SIMulation (NGSIM) open data website:\n\nITS DataHub has partnered with the Federal Highway Administration’s (FHWA’s) Next Generation SIMulation (NGSIM) program to make available detailed vehicle trajectory data and supporting data files along with the raw and processed video files from the NGSIM data collection efforts. Researchers for the NGSIM program collected the specified data on southbound US 101 and Lankershim Boulevard in Los Angeles, CA, eastbound I-80 in Emeryville, CA and Peachtree Street in Atlanta, GA.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImport Data\n\n\n\n\n\n\nimport\n\n\ntime-space\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/import/import.html",
    "href": "posts/import/import.html",
    "title": "Import Data",
    "section": "",
    "text": "After completing this post, you will be able to:\n\n\n\n\nProgrammatically download and save raw NGSIM data\n\nPartition the raw data by location and save as separate parquet files without loading them into memory\n\nCreate this time-space diagram:"
  },
  {
    "objectID": "posts/import/import.html#download-raw-data",
    "href": "posts/import/import.html#download-raw-data",
    "title": "Import Data",
    "section": "Download raw data",
    "text": "Download raw data\nWe begin by downloading the NGSIM data from their website. Generally, you do this by clicking the download button on the data page. In R, you can download the data as follows. First, you create a data folder in your desired location:\n\ndir.create(\"data\")\n\nNext, utilize the download.file function to download the NGSIM data:\n\ndate_today &lt;- format(Sys.Date(), \"%Y%m%d\")\ndata_url &lt;- paste0(\"https://datahub.transportation.gov/api/views/8ect-6jqj/rows.csv?date=\", date_today, \"&accessType=DOWNLOAD\")\n\n# Download\ndownload.file(url = data_url, destfile = \"data/ngsim_data.csv\")\n\nIn the code chunk above, Sys.Date() provides today’s date which we name as date_today. Then data_url is the URL built with date_today as that is how the ITS hub provides access to the data. This is the URL that we then provide to the download.file function along with the location and name of the csv file.\nThe time to download this 1.4 GB file depends on your internet speed. It took about 10 minutes on a 60 MB/s connection I tested."
  },
  {
    "objectID": "posts/import/import.html#partition-ngsim-data-by-location",
    "href": "posts/import/import.html#partition-ngsim-data-by-location",
    "title": "Import Data",
    "section": "Partition NGSIM data by location",
    "text": "Partition NGSIM data by location\nThe NGSIM data has millions of rows and has a disk size of 1.4 GB! You can load all the data in R using the awesome data.table package:\n\nlibrary(data.table)\nngsim_data &lt;- fread(\"data/ngsim_data.csv\")\n\nNote that R uses both the &lt;- and = as assignment operators. But &lt;- is used more frequently.\nLoading this data in R may be possible with good enough computer memory, but may not be a good idea due to the following reasons:\n\nIntensive calculations may slow down and even crash your R session when all the data is used simultaneously.\n\nYou may be interested in analyzing only part of the data, e.g., only the Interstate-80 trajectories.\n\nSo, we use the arrow package to partition the data by location and use tools to minimize loading large parts of data in memory (all data imported in R is available in computer memory).\n\nOpen NGSIM\n\narrow has this open_dataset function that lets you peek inside the data without actually loading it into memory.\n\nlibrary(arrow)\nngsim_data &lt;- open_dataset(\n1  sources = \"data/ngsim_data.csv\",\n2  col_types = schema(Location = string()),\n3  format = \"csv\"\n)\n\n\n1\n\nProvide the location and name of the data file.\n\n\n2\n\nOptionally provide the column types. For example, read the Location column as a string type.\n\n\n3\n\nSpecify the format of the input file.\n\n\n\n\nThis does not read the entire dataset, but rather creates an ArrowObject that provides metadata:\n\nngsim_data\n\nFileSystemDataset with 1 csv file\nVehicle_ID: int64\nFrame_ID: int64\nTotal_Frames: int64\nGlobal_Time: int64\nLocal_X: double\nLocal_Y: double\nGlobal_X: double\nGlobal_Y: double\nv_length: double\nv_Width: double\nv_Class: int64\nv_Vel: double\nv_Acc: double\nLane_ID: int64\nO_Zone: int64\nD_Zone: int64\nInt_ID: int64\nSection_ID: int64\nDirection: int64\nMovement: int64\nPreceding: int64\nFollowing: int64\nSpace_Headway: double\nTime_Headway: double\nLocation: string\n\n\nHere you see several variables with their types. We can now use the Location variable to partition data.\n\n\nPartition by location and save\nNow we load the dplyr package to group the data by Location and then use arrow to save it.\n\n1data_by_location_folder &lt;- \"data/ngsim_location\"\n\nngsim_data |&gt;\n2  dplyr::group_by(Location) |&gt;\n3  write_dataset(path = data_by_location_folder, format = \"parquet\")\n\n\n1\n\nPath to the folder where you want to store files.\n\n\n2\n\nGroup by the Location variable.\n\n\n3\n\nSave partitioned data in the specified location as a parquet file. Parquet files are column-based and are faster to read and write than csv files.\n\n\n\n\nThe |&gt; is a pipe operator in R. It means “and then”. For example, take ngsim_data and then group it by Location.\nEach saved file is named as part-0.parquet in its own folder:\n\nThe beauty of the above code is that new files are created and saved without loading any data into memory. So, you don’t need to wait to get to your desired data for analysis.\nLet’s see the size of each file:\n\nlibrary(tibble)\ntibble(\n  files = list.files(data_by_location_folder, recursive = TRUE),\n  size_MB = file.size(file.path(data_by_location_folder, files)) / 1024^2\n)\n\n# A tibble: 4 × 2\n  files                              size_MB\n  &lt;chr&gt;                                &lt;dbl&gt;\n1 Location=i-80/part-0.parquet         290. \n2 Location=lankershim/part-0.parquet   118. \n3 Location=peachtree/part-0.parquet     67.3\n4 Location=us-101/part-0.parquet       289. \n\n\nThese are small datasets that most computers can easily deal with."
  },
  {
    "objectID": "posts/import/import.html#create-a-time-space-diagram-with-interstate-80-data",
    "href": "posts/import/import.html#create-a-time-space-diagram-with-interstate-80-data",
    "title": "Import Data",
    "section": "Create a time-space diagram with Interstate-80 data",
    "text": "Create a time-space diagram with Interstate-80 data\nAccording to the official web-page, Interstate-80 (I80 from now on) data consists of vehicle trajectories collected between 4 pm - 5:30 pm on April 13, 2005.\nTo create a time-space diagram, we need variables for time (x-axis) and space (y-axis). Local_Y represents the longitudinal position of the front end of vehicles, so we can plot it on y-axis. However, there is only an interger encoded time variable in the data Global_Time. Therefore, the first step is to create a new column that contains the actual time.\n\nOpen the I80 data and find the time range\nWe start by opening the I80 dataset:\n\ni80 &lt;- open_dataset(paste0(data_by_location_folder, \"/Location=i-80\"))\n\ni80\n\nFileSystemDataset with 1 Parquet file\nVehicle_ID: int64\nFrame_ID: int64\nTotal_Frames: int64\nGlobal_Time: int64\nLocal_X: double\nLocal_Y: double\nGlobal_X: double\nGlobal_Y: double\nv_length: double\nv_Width: double\nv_Class: int64\nv_Vel: double\nv_Acc: double\nLane_ID: int64\nO_Zone: int64\nD_Zone: int64\nInt_ID: int64\nSection_ID: int64\nDirection: int64\nMovement: int64\nPreceding: int64\nFollowing: int64\nSpace_Headway: double\nTime_Headway: double\n\n\nUsing the lubridate package, we create a new column actual_time:\n\nlibrary(dplyr)\nlibrary(lubridate)\ntime_range &lt;- i80 |&gt;\n1  select(Global_Time) |&gt;\n2  collect() |&gt;\n3  mutate(actual_time = as_datetime(Global_Time / 1000,\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |&gt;\n4  pull(actual_time) |&gt;\n5  range()\n\n\n1\n\nSelect the Global_Time column without loading it.\n\n\n2\n\nCollect the selected data into memory.\n\n\n3\n\nCreate the actual_time column by utilizing lubridate::as_datetime. Note that the appropriate timezone is provided.\n\n\n4\n\nPull out the actual_time column as a vector. A vector in R is a collection of numbers.\n\n\n5\n\nFind the range (min. and max.) of the time.\n\n\n\n\nLet’s see the range:\n\ntime_range\n\n[1] \"2005-04-13 15:58:55 PDT\" \"2005-04-13 17:32:14 PDT\"\n\n\nThis result indicates that the data was collected between 3:58 pm to 5:32 pm on April 13, 2005 which matches the description on the web-page.\n\n\nPartition the I80 data\nThe description further says:\n\nA total of 45 minutes of data are available in the full dataset, segmented into three 15-minute periods: 4:00 p.m. to 4:15 p.m.; 5:00 p.m. to 5:15 p.m.; and 5:15 p.m. to 5:30 p.m.\n\nHowever, the time_range indicates that data is available for 90 minutes rather than 45 minutes. Here, we follow the description and partition the I80 data by the specified periods:\n\n# Specify the time periods:\nfirst_period_starts &lt;- time_range[1]\nfirst_period_ends &lt;- as_datetime(\"2005-04-13 16:15:00\", tz = \"America/Los_Angeles\")\nsecond_period_starts &lt;- as_datetime(\"2005-04-13 17:00:00\", tz = \"America/Los_Angeles\")\nsecond_period_ends &lt;- as_datetime(\"2005-04-13 17:15:00\", tz = \"America/Los_Angeles\")\nthird_period_ends &lt;- time_range[2]\n\n# Since Global_Time is an integer, convert the start and end vars to integers:\nfirst_period_starts &lt;- as.numeric(first_period_starts) * 1000\nfirst_period_ends &lt;- as.numeric(first_period_ends) * 1000\nsecond_period_starts &lt;- as.numeric(second_period_starts) * 1000\nsecond_period_ends &lt;- as.numeric(second_period_ends) * 1000\nthird_period_ends &lt;- as.numeric(third_period_ends) * 1000\n\n# Create the period column\ni80 |&gt;\n  mutate(period = case_when(\n    Global_Time &gt;= first_period_starts & Global_Time &lt;= first_period_ends ~ \"first\",\n    Global_Time &gt;= second_period_starts & Global_Time &lt;= second_period_ends ~ \"second\",\n    Global_Time &gt; second_period_ends & Global_Time &lt;= third_period_ends ~ \"third\"\n  )) |&gt;\n  group_by(period) |&gt;\n  write_dataset(path = \"data/I80\", format = \"parquet\")\n\nThe code above uses dplyr::case_when inside a mutate statement to create a new column that indicates the time period based on the specified start & end of each time period. Note that we did not use the actual_time column here because it does not exist in the saved parquet files. This column was created on the fly when the time_range variable was created.\nThis creates four, not three, files as expected:\n\n\n\nTime-space diagram\nLet’s create a time-space diagram of the first period in I80 dataset. We see that I80 has following lanes:\n\nopen_dataset(\"data/I80\") |&gt;\n  pull(Lane_ID, as_vector = TRUE) |&gt;\n  unique()\n\n[1] 5 6 2 3 4 1 7\n\n\nFor our diagram, we limit the data to the first three lanes only:\n\n1i80_filtered &lt;- open_dataset(\"data/I80\") |&gt;\n  filter(\n2    period %in% c(\"first\"),\n    Lane_ID %in% c(1, 2, 3)\n  ) |&gt;\n  collect() |&gt;\n  mutate(actual_time = as_datetime(Global_Time / 1000,\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |&gt;\n  arrange(Vehicle_ID, actual_time)\n\n\n1\n\nOpen partitioned I80 dataset.\n\n\n2\n\nFilter the data to contain trajectories in lanes 1, 2, and 3 during the first period only.\n\n\n\n\nNow, we use the ggplot2 function to create the diagram:\n\nlibrary(ggplot2)\ntime_space_diagram_i80 &lt;- i80_filtered |&gt;\n1  ggplot() +\n2  geom_path(\n    aes(\n3      x = actual_time,\n4      y = Local_Y,\n5      color = v_Vel,\n6      group = Vehicle_ID\n    ),\n7    alpha = 0.5\n  ) +\n8  scale_color_gradient(low = \"red\", high = \"green\") +\n9  facet_grid(Lane_ID ~ ., labeller = \"label_both\") +\n10  labs(\n    x = \"Time (HH:MM)\",\n    y = \"Longitudinal position\",\n    color = \"Speed (m/s)\"\n  ) +\n  theme_minimal()\n\ntime_space_diagram_i80\n\n\n1\n\nStart by calling the ggplot function.\n\n\n2\n\nUse geom_path to create continuous lines.\n\n\n3\n\nTime on x-axis.\n\n\n4\n\nLongitudinal position (feet) on y-axis.\n\n\n5\n\nColour by vehicle speed.\n\n\n6\n\nCreate a separate line for each vehicle by specifying group as Vehicle_ID. 7. Make the lines 50% transparent.\n\n\n7\n\nUse red and green color scale.\n\n\n8\n\nCreate small but connected plots (small multiples) for each lane.\n\n\n9\n\nAdd labels to axes and colour legend.\n\n\n10\n\nUse the minimal theme to declutter the plot.\n\n\n\n\n\nggplot2 has this handy function ggsave to save the plotted image to disk:\n\n1ggsave(time_space_diagram_i80,\n2       path = \"time_space_diagram.png\",\n3       width = 11,\n4       height = 8,\n5       units = \"in\",\n6       dpi = 30)\n\n\n1\n\nSpecify the plot that you want to save.\n\n\n2\n\nProvide the full path with file name where you want to save the plotted image.\n\n\n3\n\nSpecify the width of plotted image.\n\n\n4\n\nSpecify the height of plotted image.\n\n\n5\n\nSpecify the units of width and height. \"in\" means inches.\n\n\n6\n\nSpecify the resolution of the image. Higher resolution makes crisper images but takes longer to plot than lower resolution.\n\n\n\n\nAnd we are done! Believe it or not, saving this plot took longer than any other step in this post."
  }
]