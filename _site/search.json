[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Importing, Transforming, Analyzing, and Visualizing NGSIM Data",
    "section": "",
    "text": "This page contains several posts that show how to import, transform, analyze and visualize NGSIM vehicle trajectory data using programming tools (mostly R, but sometimes Python and Julia).\nFrom the Next Generation SIMulation (NGSIM) open data website:\n\nITS DataHub has partnered with the Federal Highway Administration’s (FHWA’s) Next Generation SIMulation (NGSIM) program to make available detailed vehicle trajectory data and supporting data files along with the raw and processed video files from the NGSIM data collection efforts. Researchers for the NGSIM program collected the specified data on southbound US 101 and Lankershim Boulevard in Los Angeles, CA, eastbound I-80 in Emeryville, CA and Peachtree Street in Atlanta, GA.\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nTransform Data with Julia\n\n\n\n\n\n\n\nimport\n\n\ntransform\n\n\nTidier.jl\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n  \n\n\n\n\nTransform Data with Python\n\n\n\n\n\n\n\nimport\n\n\ntransform\n\n\npandas\n\n\npolars\n\n\njanitor\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n  \n\n\n\n\nTransform Data with R\n\n\n\n\n\n\n\nimport\n\n\ntransform\n\n\ndplyr\n\n\narrow\n\n\njanitor\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\n  \n\n\n\n\nImport Data with R\n\n\n\n\n\n\n\nimport\n\n\ntime-space\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nUmair Durrani\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/import/import.html",
    "href": "posts/import/import.html",
    "title": "Import Data with R",
    "section": "",
    "text": "After completing this post, you will be able to:\n\n\n\n\nProgrammatically download and save raw NGSIM data\n\nPartition the raw data by location and save as separate parquet files without loading them into memory\n\nCreate this time-space diagram:\n\n\nNote: The code in this post is derived from Chapter 22 of R for Data Science book."
  },
  {
    "objectID": "posts/import/import.html#download-raw-data",
    "href": "posts/import/import.html#download-raw-data",
    "title": "Import Data with R",
    "section": "Download raw data",
    "text": "Download raw data\nWe begin by downloading the NGSIM data from their website. Generally, you do this by clicking the download button on the data page. In R, you can download the data as follows. First, you create a data folder in your desired location:\n\ndir.create(\"data\")\n\nNext, utilize the download.file function to download the NGSIM data:\n\ndate_today &lt;- format(Sys.Date(), \"%Y%m%d\")\ndata_url &lt;- paste0(\"https://datahub.transportation.gov/api/views/8ect-6jqj/rows.csv?date=\", date_today, \"&accessType=DOWNLOAD\")\n\n# Download\ndownload.file(url = data_url, destfile = \"data/ngsim_data.csv\")\n\nIn the code chunk above, Sys.Date() provides today’s date which we name as date_today. Then data_url is the URL built with date_today as that is how the ITS hub provides access to the data. This is the URL that we then provide to the download.file function along with the location and name of the csv file.\nThe time to download this 1.4 GB file depends on your internet speed. It took about 10 minutes on a 60 MB/s connection I tested."
  },
  {
    "objectID": "posts/import/import.html#partition-ngsim-data-by-location",
    "href": "posts/import/import.html#partition-ngsim-data-by-location",
    "title": "Import Data with R",
    "section": "Partition NGSIM data by location",
    "text": "Partition NGSIM data by location\nThe NGSIM data has millions of rows and has a disk size of 1.4 GB! You can load all the data in R using the awesome data.table package:\n\nlibrary(data.table)\nngsim_data &lt;- fread(\"data/ngsim_data.csv\")\n\nNote that R uses both the &lt;- and = as assignment operators. But &lt;- is used more frequently.\nLoading this data in R may be possible with good enough computer memory, but may not be a good idea due to the following reasons:\n\nIntensive calculations may slow down and even crash your R session when all the data is used simultaneously.\n\nYou may be interested in analyzing only part of the data, e.g., only the Interstate-80 trajectories.\n\nSo, we use the arrow package to partition the data by location and use tools to minimize loading large parts of data in memory (all data imported in R is available in computer memory).\n\nOpen NGSIM\n\narrow has this open_dataset function that lets you peek inside the data without actually loading it into memory.\nHover over the annotated line numbers to see the code description.\n\nlibrary(arrow)\nngsim_data &lt;- open_dataset(\n1  sources = \"data/ngsim_data.csv\",\n2  col_types = schema(Location = string()),\n3  format = \"csv\"\n)\n\n\n1\n\nProvide the location and name of the data file.\n\n\n2\n\nOptionally provide the column types. For example, read the Location column as a string type.\n\n\n3\n\nSpecify the format of the input file.\n\n\n\n\nThis does not read the entire dataset, but rather creates an ArrowObject that provides metadata:\n\nngsim_data\n\nFileSystemDataset with 1 csv file\nVehicle_ID: int64\nFrame_ID: int64\nTotal_Frames: int64\nGlobal_Time: int64\nLocal_X: double\nLocal_Y: double\nGlobal_X: double\nGlobal_Y: double\nv_length: double\nv_Width: double\nv_Class: int64\nv_Vel: double\nv_Acc: double\nLane_ID: int64\nO_Zone: int64\nD_Zone: int64\nInt_ID: int64\nSection_ID: int64\nDirection: int64\nMovement: int64\nPreceding: int64\nFollowing: int64\nSpace_Headway: double\nTime_Headway: double\nLocation: string\n\n\nHere you see several variables with their types. We can now use the Location variable to partition data.\n\n\nPartition by location and save\nNow we load the dplyr package to group the data by Location and then use arrow to save it.\n\n1data_by_location_folder &lt;- \"data/ngsim_location\"\n\nngsim_data |&gt;\n2  dplyr::group_by(Location) |&gt;\n3  write_dataset(path = data_by_location_folder, format = \"parquet\")\n\n\n1\n\nPath to the folder where you want to store files.\n\n\n2\n\nGroup by the Location variable.\n\n\n3\n\nSave partitioned data in the specified location as a parquet file. Parquet files are column-based and are faster to read and write than csv files.\n\n\n\n\nThe |&gt; is a pipe operator in R. It means “and then”. For example, take ngsim_data and then group it by Location.\nEach saved file is named as part-0.parquet in its own folder:\n\nThe beauty of the above code is that new files are created and saved without loading any data into memory. So, you don’t need to wait to get to your desired data for analysis.\nLet’s see the size of each file:\n\nlibrary(tibble)\ntibble(\n  files = list.files(data_by_location_folder, recursive = TRUE),\n  size_MB = file.size(file.path(data_by_location_folder, files)) / 1024^2\n)\n\n\n\n  \n\n\n\nThese are small datasets that most computers can easily deal with."
  },
  {
    "objectID": "posts/import/import.html#create-a-time-space-diagram-with-interstate-80-data",
    "href": "posts/import/import.html#create-a-time-space-diagram-with-interstate-80-data",
    "title": "Import Data with R",
    "section": "Create a time-space diagram with Interstate-80 data",
    "text": "Create a time-space diagram with Interstate-80 data\nAccording to the official web-page, Interstate-80 (I80 from now on) data consists of vehicle trajectories collected between 4 pm - 5:30 pm on April 13, 2005.\nTo create a time-space diagram, we need variables for time (x-axis) and space (y-axis). Local_Y represents the longitudinal position of the front end of vehicles, so we can plot it on y-axis. However, there is only an interger encoded time variable in the data Global_Time. Therefore, the first step is to create a new column that contains the actual time.\n\nOpen the I80 data and find the time range\nWe start by opening the I80 dataset:\n\ni80 &lt;- open_dataset(paste0(data_by_location_folder, \"/Location=i-80\"))\n\ni80\n\nFileSystemDataset with 1 Parquet file\nVehicle_ID: int64\nFrame_ID: int64\nTotal_Frames: int64\nGlobal_Time: int64\nLocal_X: double\nLocal_Y: double\nGlobal_X: double\nGlobal_Y: double\nv_length: double\nv_Width: double\nv_Class: int64\nv_Vel: double\nv_Acc: double\nLane_ID: int64\nO_Zone: int64\nD_Zone: int64\nInt_ID: int64\nSection_ID: int64\nDirection: int64\nMovement: int64\nPreceding: int64\nFollowing: int64\nSpace_Headway: double\nTime_Headway: double\n\n\nUsing the lubridate package, we create a new column actual_time:\n\nlibrary(dplyr)\nlibrary(lubridate)\ntime_range &lt;- i80 |&gt;\n1  select(Global_Time) |&gt;\n2  collect() |&gt;\n3  mutate(actual_time = as_datetime(Global_Time / 1000,\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |&gt;\n4  pull(actual_time) |&gt;\n5  range()\n\n\n1\n\nSelect the Global_Time column without loading it.\n\n\n2\n\nCollect the selected data into memory.\n\n\n3\n\nCreate the actual_time column by utilizing lubridate::as_datetime. Note that the appropriate timezone is provided.\n\n\n4\n\nPull out the actual_time column as a vector. A vector in R is a collection of numbers.\n\n\n5\n\nFind the range (min. and max.) of the time.\n\n\n\n\nLet’s see the range:\n\ntime_range\n\n[1] \"2005-04-13 15:58:55 PDT\" \"2005-04-13 17:32:14 PDT\"\n\n\nThis result indicates that the data was collected between 3:58 pm to 5:32 pm on April 13, 2005 which matches the description on the web-page.\n\n\nPartition the I80 data\nThe description further says:\n\nA total of 45 minutes of data are available in the full dataset, segmented into three 15-minute periods: 4:00 p.m. to 4:15 p.m.; 5:00 p.m. to 5:15 p.m.; and 5:15 p.m. to 5:30 p.m.\n\nHowever, the time_range indicates that data is available for 90 minutes rather than 45 minutes. Here, we follow the description and partition the I80 data by the specified periods:\n\n# Specify the time periods:\nfirst_period_starts &lt;- time_range[1]\nfirst_period_ends &lt;- as_datetime(\"2005-04-13 16:15:00\", tz = \"America/Los_Angeles\")\nsecond_period_starts &lt;- as_datetime(\"2005-04-13 17:00:00\", tz = \"America/Los_Angeles\")\nsecond_period_ends &lt;- as_datetime(\"2005-04-13 17:15:00\", tz = \"America/Los_Angeles\")\nthird_period_ends &lt;- time_range[2]\n\n# Since Global_Time is an integer, convert the start and end vars to integers:\nfirst_period_starts &lt;- as.numeric(first_period_starts) * 1000\nfirst_period_ends &lt;- as.numeric(first_period_ends) * 1000\nsecond_period_starts &lt;- as.numeric(second_period_starts) * 1000\nsecond_period_ends &lt;- as.numeric(second_period_ends) * 1000\nthird_period_ends &lt;- as.numeric(third_period_ends) * 1000\n\n# Create the period column\ni80 |&gt;\n  mutate(period = case_when(\n    Global_Time &gt;= first_period_starts & Global_Time &lt;= first_period_ends ~ \"first\",\n    Global_Time &gt;= second_period_starts & Global_Time &lt;= second_period_ends ~ \"second\",\n    Global_Time &gt; second_period_ends & Global_Time &lt;= third_period_ends ~ \"third\"\n  )) |&gt;\n  group_by(period) |&gt;\n  write_dataset(path = \"data/I80\", format = \"parquet\")\n\nThe code above uses dplyr::case_when inside a mutate statement to create a new column that indicates the time period based on the specified start & end of each time period. Note that we did not use the actual_time column here because it does not exist in the saved parquet files. This column was created on the fly when the time_range variable was created.\nThis creates four, not three, files as expected:\n\n\n\nTime-space diagram\nLet’s create a time-space diagram of the first period in I80 dataset. We see that I80 has following lanes:\n\nopen_dataset(\"data/I80\") |&gt;\n  pull(Lane_ID, as_vector = TRUE) |&gt;\n  unique()\n\n[1] 5 6 2 3 4 1 7\n\n\nFor our diagram, we limit the data to the first three lanes only:\n\n1i80_filtered &lt;- open_dataset(\"data/I80\") |&gt;\n  filter(\n2    period %in% c(\"first\"),\n    Lane_ID %in% c(1, 2, 3)\n  ) |&gt;\n  collect() |&gt;\n  mutate(actual_time = as_datetime(Global_Time / 1000,\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |&gt;\n3  arrange(Vehicle_ID, actual_time)\n\n\n1\n\nOpen partitioned I80 dataset.\n\n\n2\n\nFilter the data to contain trajectories in lanes 1, 2, and 3 during the first period only.\n\n\n3\n\nSort by Vehicle_ID and actual_time.\n\n\n\n\nNow, we use the ggplot2 package to create the diagram:\n\nlibrary(ggplot2)\ntime_space_diagram_i80 &lt;- i80_filtered |&gt;\n1  ggplot() +\n2  geom_path(\n    aes(\n3      x = actual_time,\n4      y = Local_Y,\n5      color = v_Vel,\n6      group = Vehicle_ID\n    ),\n7    alpha = 0.5\n  ) +\n8  scale_color_gradient(low = \"red\", high = \"green\") +\n9  facet_grid(Lane_ID ~ ., labeller = \"label_both\") +\n10  labs(\n    x = \"Time (HH:MM)\",\n    y = \"Longitudinal position\",\n    color = \"Speed (m/s)\"\n  ) +\n  theme_minimal()\n\ntime_space_diagram_i80\n\n\n1\n\nStart by calling the ggplot function.\n\n\n2\n\nUse geom_path to create continuous lines.\n\n\n3\n\nTime on x-axis.\n\n\n4\n\nLongitudinal position (feet) on y-axis.\n\n\n5\n\nColour by vehicle speed.\n\n\n6\n\nCreate a separate line for each vehicle by specifying group as Vehicle_ID. 7. Make the lines 50% transparent.\n\n\n7\n\nUse red and green color scale.\n\n\n8\n\nCreate small but connected plots (small multiples) for each lane.\n\n\n9\n\nAdd labels to axes and colour legend.\n\n\n10\n\nUse the minimal theme to declutter the plot.\n\n\n\n\n\nggplot2 has this handy function ggsave to save the plotted image to disk:\n\n1ggsave(time_space_diagram_i80,\n2       path = \"time_space_diagram.png\",\n3       width = 11,\n4       height = 8,\n5       units = \"in\",\n6       dpi = 30)\n\n\n1\n\nSpecify the plot that you want to save.\n\n\n2\n\nProvide the full path with file name where you want to save the plotted image.\n\n\n3\n\nSpecify the width of plotted image.\n\n\n4\n\nSpecify the height of plotted image.\n\n\n5\n\nSpecify the units of width and height. \"in\" means inches.\n\n\n6\n\nSpecify the resolution of the image. Higher resolution makes crisper images but takes longer to plot than lower resolution.\n\n\n\n\nAnd we are done! Believe it or not, saving this plot took longer than any other step in this post."
  },
  {
    "objectID": "posts/transform/transform.html",
    "href": "posts/transform/transform.html",
    "title": "Transform Data",
    "section": "",
    "text": "#| echo: false\nreticulate::use_python(\"C:\\\\Users\\\\umair\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python.exe\")"
  },
  {
    "objectID": "posts/transform/transform.html#load-parquet-file",
    "href": "posts/transform/transform.html#load-parquet-file",
    "title": "Transform Data",
    "section": "Load parquet file",
    "text": "Load parquet file\n\nRPython\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\npath_to_first_period_file &lt;- \"data/i80_period1.parquet\"\ndata_R &lt;- arrow::read_parquet(file = path_to_first_period_file)\n\ndata_R\n\n\n\nimport polars as pl\n\npath_to_first_period_file = \"data/i80_period1.parquet\"\ndata_py = pl.read_parquet(path_to_first_period_file)\n\ndata_py.head()\n\n\nshape: (5, 24)\n\n\n\nVehicle_ID\nFrame_ID\nTotal_Frames\nGlobal_Time\nLocal_X\nLocal_Y\nGlobal_X\nGlobal_Y\nv_length\nv_Width\nv_Class\nv_Vel\nv_Acc\nLane_ID\nO_Zone\nD_Zone\nInt_ID\nSection_ID\nDirection\nMovement\nPreceding\nFollowing\nSpace_Headway\nTime_Headway\n\n\ni32\ni32\ni32\ni64\nf64\nf64\nf64\nf64\nf64\nf64\ni32\nf64\nf64\ni32\ni32\ni32\ni32\ni32\ni32\ni32\ni32\ni32\nf64\nf64\n\n\n\n\n3027\n8493\n813\n1113433984200\n53.115\n363.266\n6.0428e6\n2.1334e6\n15.3\n7.4\n2\n21.46\n-8.14\n5\nnull\nnull\nnull\nnull\nnull\nnull\n3014\n3032\n64.23\n2.99\n\n\n3214\n9115\n708\n1113434046400\n67.931\n655.629\n6.0428e6\n2.1337e6\n13.8\n6.3\n2\n15.37\n11.2\n6\nnull\nnull\nnull\nnull\nnull\nnull\n3221\n3229\n31.71\n2.06\n\n\n3199\n9329\n575\n1113434067800\n17.026\n1237.592\n6.0427e6\n2.1343e6\n14.4\n5.9\n2\n39.3\n0.0\n2\nnull\nnull\nnull\nnull\nnull\nnull\n3188\n3206\n72.36\n1.84\n\n\n3159\n8919\n572\n1113434026800\n16.541\n306.905\n6.0428e6\n2.1334e6\n16.4\n5.9\n2\n14.71\n3.61\n2\nnull\nnull\nnull\nnull\nnull\nnull\n3152\n3171\n51.9\n3.53\n\n\n3314\n9324\n616\n1113434067300\n28.846\n65.807\n6.0429e6\n2.1331e6\n14.8\n6.4\n2\n36.24\n0.0\n3\nnull\nnull\nnull\nnull\nnull\nnull\n3301\n0\n103.26\n2.85"
  },
  {
    "objectID": "posts/transform/transform.html#clean-dataframe-names",
    "href": "posts/transform/transform.html#clean-dataframe-names",
    "title": "Transform Data",
    "section": "Clean dataframe names",
    "text": "Clean dataframe names\n\nRPython\n\n\nlibrary(janitor)\ndata_R &lt;- janitor::clean_names(data_R) \n\n\n\nimport pandas as pd\nimport pyarrow\nimport janitor\ndata_py = data_py.to_pandas()\ndata_py = data_py.clean_names()\n\ndata_py.head()\n\n\n\n\n\n\n\n\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\n...\no_zone\nd_zone\nint_id\nsection_id\ndirection\nmovement\npreceding\nfollowing\nspace_headway\ntime_headway\n\n\n\n\n0\n3027\n8493\n813\n1113433984200\n53.115\n363.266\n6042839.372\n2133434.927\n15.3\n7.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3014\n3032\n64.23\n2.99\n\n\n1\n3214\n9115\n708\n1113434046400\n67.931\n655.629\n6042817.933\n2133726.884\n13.8\n6.3\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3221\n3229\n31.71\n2.06\n\n\n2\n3199\n9329\n575\n1113434067800\n17.026\n1237.592\n6042683.444\n2134296.961\n14.4\n5.9\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3188\n3206\n72.36\n1.84\n\n\n3\n3159\n8919\n572\n1113434026800\n16.541\n306.905\n6042810.096\n2133374.273\n16.4\n5.9\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3152\n3171\n51.90\n3.53\n\n\n4\n3314\n9324\n616\n1113434067300\n28.846\n65.807\n6042851.778\n2133136.617\n14.8\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3301\n0\n103.26\n2.85\n\n\n\n\n5 rows × 24 columns"
  },
  {
    "objectID": "posts/transform/transform.html#how-to-create-a-time-column",
    "href": "posts/transform/transform.html#how-to-create-a-time-column",
    "title": "Transform Data",
    "section": "How to create a time column?",
    "text": "How to create a time column?\n\nRPython\n\n\nlibrary(lubridate)\n\ndata_R &lt;- data_R |&gt;\n  dplyr::mutate(actual_time = lubridate::as_datetime(global_time / 1000, \n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  ))\ndata_R &lt;- data_R |&gt; \n  group_by(vehicle_id) |&gt; \n  mutate(time = (0:(n()-1))/10) |&gt; \n  ungroup()\n\nhead(data_R)"
  },
  {
    "objectID": "posts/transform/transform_py.html",
    "href": "posts/transform/transform_py.html",
    "title": "Transform Data with Python",
    "section": "",
    "text": "Note\n\n\n\nThis is the second post in the NGSIM data analysis series. Previous post:\n\nImport data\nIn the previous post, we partitioned the Interstate 80 (I80) vehicle trajectories data by time and then saved it on disk:\nWe now make use of the parquet file in the period=first directory for learning to transform data. Since this file is part of partitioned data, I saved it as a separate parquet file (i80_period1.parquet) in a different location.\nNow, we read the i80_period1.parquet file:"
  },
  {
    "objectID": "posts/transform/transform_py.html#clean-dataframe-names",
    "href": "posts/transform/transform_py.html#clean-dataframe-names",
    "title": "Transform Data with Python",
    "section": "Clean dataframe names",
    "text": "Clean dataframe names\nAs you can see above, the column names are in good shape i.e., without any spaces. However, it is easier typing lowercase letters than the sentence case. So, we use the clean_names function from the janitor package to make all column names lowercase. If the column names have spaces or periods in them, clean_names would replace them with underscores.\nUsing pyjanitor requires the data to be a pandas dataframe. But we loaded the data from a parquet file using the polars package, so we need to first convert the polars dataframe to a pandas dataframe. This further requires importing the pyarrow package:\n\n# Installation:\n# pip install pyjanitor\n# pip install pyarrow\n# pip install pandas\n\nimport pandas as pd\nimport pyarrow\nimport janitor\ndata_py = data_py.to_pandas()\ndata_py = data_py.clean_names()\n\ndata_py.head()\n\n\n\n\n\n\n\n\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\n...\no_zone\nd_zone\nint_id\nsection_id\ndirection\nmovement\npreceding\nfollowing\nspace_headway\ntime_headway\n\n\n\n\n0\n3027\n8493\n813\n1113433984200\n53.115\n363.266\n6042839.372\n2133434.927\n15.3\n7.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3014\n3032\n64.23\n2.99\n\n\n1\n3214\n9115\n708\n1113434046400\n67.931\n655.629\n6042817.933\n2133726.884\n13.8\n6.3\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3221\n3229\n31.71\n2.06\n\n\n2\n3199\n9329\n575\n1113434067800\n17.026\n1237.592\n6042683.444\n2134296.961\n14.4\n5.9\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3188\n3206\n72.36\n1.84\n\n\n3\n3159\n8919\n572\n1113434026800\n16.541\n306.905\n6042810.096\n2133374.273\n16.4\n5.9\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3152\n3171\n51.90\n3.53\n\n\n4\n3314\n9324\n616\n1113434067300\n28.846\n65.807\n6042851.778\n2133136.617\n14.8\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3301\n0\n103.26\n2.85\n\n\n\n\n5 rows × 24 columns"
  },
  {
    "objectID": "posts/transform/transform_py.html#how-to-create-a-time-column",
    "href": "posts/transform/transform_py.html#how-to-create-a-time-column",
    "title": "Transform Data with Python",
    "section": "How to create a time column?",
    "text": "How to create a time column?\nSince vehicle trajectories change over time, it is nice to see these changes over different time periods. However, the gloabl_time column in this dataset contains integers rather than the actual time. So, we create a new column called actual_time by dividing the global_time by 1000 and converting it to a datetime object.\nIn Python, this can be done via pandas.to_datetime. Note that we specify the time zone to be America/Los_Angeles.\n\ndata_py['actual_time'] = pd.to_datetime(data_py['global_time'] / 1000, \n                                    unit='s', origin='1970-01-01', utc=True)\ndata_py['actual_time'] = data_py['actual_time'].dt.tz_convert('America/Los_Angeles')\n\ndata_py.head()\n\n\n\n\n\n\n\n\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\n...\nd_zone\nint_id\nsection_id\ndirection\nmovement\npreceding\nfollowing\nspace_headway\ntime_headway\nactual_time\n\n\n\n\n0\n3027\n8493\n813\n1113433984200\n53.115\n363.266\n6042839.372\n2133434.927\n15.3\n7.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n3014\n3032\n64.23\n2.99\n2005-04-13 16:13:04.200000048-07:00\n\n\n1\n3214\n9115\n708\n1113434046400\n67.931\n655.629\n6042817.933\n2133726.884\n13.8\n6.3\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n3221\n3229\n31.71\n2.06\n2005-04-13 16:14:06.400000095-07:00\n\n\n2\n3199\n9329\n575\n1113434067800\n17.026\n1237.592\n6042683.444\n2134296.961\n14.4\n5.9\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n3188\n3206\n72.36\n1.84\n2005-04-13 16:14:27.799999952-07:00\n\n\n3\n3159\n8919\n572\n1113434026800\n16.541\n306.905\n6042810.096\n2133374.273\n16.4\n5.9\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n3152\n3171\n51.90\n3.53\n2005-04-13 16:13:46.799999952-07:00\n\n\n4\n3314\n9324\n616\n1113434067300\n28.846\n65.807\n6042851.778\n2133136.617\n14.8\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n3301\n0\n103.26\n2.85\n2005-04-13 16:14:27.299999952-07:00\n\n\n\n\n5 rows × 25 columns\n\n\n\nNote that the data is not in the correct order. The vehicle_ids in the first two rows are 3027 and 3214. However, we know that the same vehicle was observed for several seconds. This means that we should see a given vehicle_id repeated over multiple rows consecutively. We therefore sort by vehicle_id and frame_id:\n\n## First: Sort by Vehicle ID and Time\ndata_py = data_py.sort_values(by = [\"vehicle_id\", \"frame_id\"])\n\ndata_py.head()\n\n\n\n\n\n\n\n\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\n...\nd_zone\nint_id\nsection_id\ndirection\nmovement\npreceding\nfollowing\nspace_headway\ntime_headway\nactual_time\n\n\n\n\n1142997\n1\n12\n884\n1113433136100\n16.884\n48.213\n6042842.116\n2133117.662\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.099999905-07:00\n\n\n1043434\n1\n13\n884\n1113433136200\n16.938\n49.463\n6042842.012\n2133118.909\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.200000048-07:00\n\n\n272197\n1\n14\n884\n1113433136300\n16.991\n50.712\n6042841.908\n2133120.155\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.299999952-07:00\n\n\n771912\n1\n15\n884\n1113433136400\n17.045\n51.963\n6042841.805\n2133121.402\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.400000095-07:00\n\n\n1036275\n1\n16\n884\n1113433136500\n17.098\n53.213\n6042841.701\n2133122.649\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.500000-07:00\n\n\n\n\n5 rows × 25 columns\n\n\n\nWhen we want to compare several vehicle trajectories, e.g., how their speeds change over time regardless of when they were observed, we’d want a common time scale. The NGSIM documentation describes that vehicles were observed at a resolution of 0.1 seconds. So, we can create atime variable for each vehicle that starts at 0 and ends at (n-1)/10 where n = number of rows for which a vehicle_id is repeated.\nWe first define a function calculate_time_elapsed that takes in a dataframe and returns the sequence from 0 to (n-1)/10 with a step size of 0.1 as a new column. Then we apply this function on the pandas dataframe:\n\ndef calculate_time_elapsed(group_df):\n    num_rows = len(group_df)\n    group_df['time'] = [i / 10.0 for i in range(num_rows)]\n    return group_df\n\n# Add the time elapsed column to the DataFrame within each group\ndata_py = data_py.groupby('vehicle_id').apply(calculate_time_elapsed)\n\ndata_py.head()\n\n\n\n\n\n\n\n\n\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\n...\nint_id\nsection_id\ndirection\nmovement\npreceding\nfollowing\nspace_headway\ntime_headway\nactual_time\ntime\n\n\nvehicle_id\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n1142997\n1\n12\n884\n1113433136100\n16.884\n48.213\n6042842.116\n2133117.662\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.099999905-07:00\n0.0\n\n\n1043434\n1\n13\n884\n1113433136200\n16.938\n49.463\n6042842.012\n2133118.909\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.200000048-07:00\n0.1\n\n\n272197\n1\n14\n884\n1113433136300\n16.991\n50.712\n6042841.908\n2133120.155\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.299999952-07:00\n0.2\n\n\n771912\n1\n15\n884\n1113433136400\n17.045\n51.963\n6042841.805\n2133121.402\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.400000095-07:00\n0.3\n\n\n1036275\n1\n16\n884\n1113433136500\n17.098\n53.213\n6042841.701\n2133122.649\n14.3\n6.4\n...\nNaN\nNaN\nNaN\nNaN\n0\n0\n0.0\n0.0\n2005-04-13 15:58:56.500000-07:00\n0.4\n\n\n\n\n5 rows × 26 columns"
  },
  {
    "objectID": "posts/transform/transform_r.html",
    "href": "posts/transform/transform_r.html",
    "title": "Transform Data with R",
    "section": "",
    "text": "Note\n\n\n\nThis is the second post in the NGSIM data analysis series. Previous post:\n\nImport data\nIn the previous post, we partitioned the Interstate 80 (I80) vehicle trajectories data by time and then saved it on disk:\nWe now make use of the parquet file in the period=first directory for learning to transform data. Since this file is part of partitioned data, I saved it as a separate parquet file in a different location as shown below:\nlibrary(arrow)\nlibrary(dplyr)\n\npath_to_partitioned_first_period_file &lt;- \"D:/ngsim/posts/import/data/I80/period=first/part-0.parquet\"\n\n1open_dataset(path_to_partitioned_first_period_file) |&gt;\n2  dplyr::collect() |&gt;\n3  arrow::write_parquet(sink = \"data/i80_period1.parquet\")\n\n\n1\n\nOpen the part-0.parquet.\n\n\n2\n\nLoad it into memory.\n\n\n3\n\nSave it as i80_period1.parquet under the data directory.\nNow, we read the i80_period1.parquet file:"
  },
  {
    "objectID": "posts/transform/transform_r.html#load-parquet-file",
    "href": "posts/transform/transform_r.html#load-parquet-file",
    "title": "Transform Data with R",
    "section": "Load parquet file",
    "text": "Load parquet file\nReading the parquet file requires the arrow package:\n\nlibrary(arrow)\nlibrary(dplyr)\n\npath_to_first_period_file &lt;- \"data/i80_period1.parquet\"\ndata_R &lt;- arrow::read_parquet(file = path_to_first_period_file)\n\nhead(data_R)"
  },
  {
    "objectID": "posts/transform/transform_r.html#clean-dataframe-names",
    "href": "posts/transform/transform_r.html#clean-dataframe-names",
    "title": "Transform Data with R",
    "section": "Clean dataframe names",
    "text": "Clean dataframe names\nAs you can see above, the column names are in good shape i.e., without any spaces. However, it is easier typing lowercase letters than the sentence case. So, we use the clean_names function from the janitor package to make all column names lowercase. If the column names have spaces or periods in them, clean_names would replace them with underscores.\n\nlibrary(janitor)\ndata_R &lt;- janitor::clean_names(data_R) \n\nhead(data_R)"
  },
  {
    "objectID": "posts/transform/transform_r.html#how-to-create-a-time-column",
    "href": "posts/transform/transform_r.html#how-to-create-a-time-column",
    "title": "Transform Data with R",
    "section": "How to create a time column?",
    "text": "How to create a time column?\nSince vehicle trajectories change over time, it is nice to see these changes over different time periods. However, the gloabl_time column in this dataset contains integers rather than the actual time. So, we create a new column called actual_time by dividing the global_time by 1000 and converting it to a datetime object.\nIn R, this can be done via lubridate::as_datetime. Note that we specify the time zone to be America/Los_Angeles.\n\nlibrary(lubridate)\n\ndata_R &lt;- data_R |&gt;\n  dplyr::mutate(actual_time = lubridate::as_datetime(global_time / 1000, \n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  ))\n\nhead(data_R)\n\n\n\n  \n\n\n\nNote that the data is not in the correct order. The vehicle_ids in the first two rows are 3027 and 3214. However, we know that the same vehicle was observed for several seconds. This means that we should see a given vehicle_id repeated over multiple rows consecutively. We therefore sort by vehicle_id and frame_id:\n\n## First: Sort by Vehicle ID and Time\ndata_R &lt;- data_R |&gt; \n  dplyr::arrange(vehicle_id, frame_id)\n\nhead(data_R)\n\n\n\n  \n\n\n\nWhen we want to compare several vehicle trajectories, e.g., how their speeds change over time regardless of when they were observed, we’d want a common time scale. The NGSIM documentation describes that vehicles were observed at a resolution of 0.1 seconds. So, we can create atime variable for each vehicle that starts at 0 and ends at (n-1)/10 where n = number of rows for which a vehicle_id is repeated:\n\ndata_R &lt;- data_R |&gt; \n1  dplyr::group_by(vehicle_id) |&gt;\n2  dplyr::mutate(time = (0:(dplyr::n()-1))/10) |&gt;\n3  dplyr::ungroup()\n\nhead(data_R)\n\n\n1\n\nGroup by vehicle_id so that time is calculated for each vehicle separately.\n\n\n2\n\ndplyr::n() gives the group size.\n\n\n3\n\nDon’t forget to ungroup."
  },
  {
    "objectID": "posts/transform/transform_r.html#how-to-create-variables-for-the-preceding-vehicle",
    "href": "posts/transform/transform_r.html#how-to-create-variables-for-the-preceding-vehicle",
    "title": "Transform Data with R",
    "section": "How to create variables for the preceding vehicle?",
    "text": "How to create variables for the preceding vehicle?\nWe’d often need velocity, acceleration, and other variables for the preceding vehicle (vehicle in front of the subject vehicle). These variables can be useful in car-following modeling.\nIn this dataset, preceding vehicle variables do not exist as separate columns. The only relevant column is preceding which is the identifier of the preceding vehicle. But the data also contains the subject vehicle identifier vehicle_id, along with these variables:\n\nlocal_y: longitudinal position of the front end of the subject vehicle (feet)\n\nlocal_x: lateral position of the front end of the subject vehicle (feet)\n\nv_length and v_width are the length and width of the subject vehicle (feet)\n\nv_class is the class of the subject vehicle, i.e., 1 = motorcycle, 2 = car, and 3 = heavy vehicle (bus/truck)\n\nv_vel and v_acc are the velocity (ft/s) and acceleration (ft/s/s) of the subject vehicle\n\nOur goal now is to create new columns of the above variables for the preceding vehicle. To this end, we look for the value of preceding in the vehicle_id column at a given value of frame_id (identifier of time frame) and then grab the value of variable e.g., v_vel at that frame_id:\n\n## Create new cols\ndata_R &lt;- data_R |&gt; \n1  dplyr::group_by(frame_id) |&gt;\n2  dplyr::mutate(preceding_local_y = local_y[match(preceding, vehicle_id)],\n                preceding_local_x = local_x[match(preceding, vehicle_id)],\n                preceding_length = v_length[match(preceding, vehicle_id)],\n                preceding_width = v_width[match(preceding, vehicle_id)],\n                preceding_class = v_class[match(preceding, vehicle_id)],\n                preceding_vel = v_vel[match(preceding, vehicle_id)],\n                preceding_acc = v_acc[match(preceding, vehicle_id)]) |&gt; \n  dplyr::ungroup()\n\nhead(data_R)\n\n\n1\n\nGrouping by time using frame_id.\n\n\n2\n\nmatch function matches the values of preceding to vehicle_id and provide the positions of these matches. Then we use the &lt;VAR&gt;[] syntax to grab the value of a variable (where &lt;VAR&gt; means the variable of interest e.g., v_vel).\n\n\n\n\n\n\n  \n\n\n\nA NA value indicates missing value. In this dataset, NA indicates that the value is missing because there was no preceding vehicle observed. For vehicle_id 1 we can see this is true because the preceding value is 0."
  },
  {
    "objectID": "posts/transform/transform_r.html#how-to-remove-undesired-columns",
    "href": "posts/transform/transform_r.html#how-to-remove-undesired-columns",
    "title": "Transform Data with R",
    "section": "How to remove undesired columns?",
    "text": "How to remove undesired columns?\nThere are several variables in this dataset that we don’t need as they are completely devoid of any value. So we remove them:\n\ndata_R &lt;- data_R |&gt;\n  select(-c(total_frames, starts_with(\"global\"), following, \n            o_zone, d_zone, int_id, section_id, direction, \n            movement), global_time) \n\nhead(data_R)"
  },
  {
    "objectID": "posts/transform/transform_r.html#how-to-transform-multiple-columns",
    "href": "posts/transform/transform_r.html#how-to-transform-multiple-columns",
    "title": "Transform Data with R",
    "section": "How to transform multiple columns?",
    "text": "How to transform multiple columns?\n\nMetric units\n\nAs discussed before, variables in this dataset have imperial units (feet, ft/s, etc.). You may want to transform the values of these variables to metric units. The conversion factor is 0.3048. Here, we utilize the across function to take all the desired columns and apply the conversion factor along with rounding to 2 decimal places:\n\n## metric units\ndata_R &lt;- data_R |&gt; \n  dplyr::mutate(dplyr::across(\n    .cols = c(dplyr::starts_with(\"local\"), dplyr::starts_with(\"v_\"), space_headway, dplyr::starts_with(\"preceding\"), -preceding, -preceding_class, -v_class),\n    .fns = ~ round(.x * .3048, 2)\n  ))\n\nhead(data_R)\n\n\n\n  \n\n\n\n\n\nConvert numbers/strings to categorical data type\nMoreover, we know that there are variables that should be treated as categorical (qualitative) rather than numbers or strings. For instance, lane_id has values 1-7 and we know that these are identifiers for lanes. Similarly, the class of a vehicle is encoded as 1, 2, and 3 but we know that these numbers do not have any quantitaive information, rather they are categories.\nIn R, categorical data is encoded as factor data type. So, we use the as.factor function to convert numbers/strings to factor data type:\n\n## factor type\ndata_R &lt;- data_R |&gt; \n  mutate(across(\n  .cols = c(vehicle_id, v_class, lane_id, preceding, preceding_class),\n  .fns = ~ as.factor(.x)\n))\n\nhead(data_R)"
  },
  {
    "objectID": "posts/transform/transform_r.html#visualization-with-one-vehicle",
    "href": "posts/transform/transform_r.html#visualization-with-one-vehicle",
    "title": "Transform Data with R",
    "section": "Visualization with one vehicle",
    "text": "Visualization with one vehicle\nCool! We are almost done with transforming our dataset. It is time to do some visualization. The last transformation we learn is to filter the data to keep only one vehicle:\n\ndata_R_veh &lt;- data_R |&gt; \n  dplyr::filter(vehicle_id == \"2\")\n\nAnd now we use ggplot2 to create a plot of velocity over time. Subject vehicle in blue and preceding vehicle in orange.\n\nlibrary(ggplot2)\nggplot(data = data_R_veh) +\n  geom_path(mapping = aes(x = time, y = v_vel), color = \"blue\") +\n  geom_path(mapping = aes(x = time, y = preceding_vel), color = \"orange\") +\n  labs(x = \"Time (s)\", y = \"Velocity (m/s)\",\n       title = \"Velocity of vehicle # 2 and its preceding vehicle\") +\n  theme_minimal()\n\n\n\n\nAs you see, the lead vehicle speed is not seen after about 17 seconds. This is because the lead vehicle changed lanes. This can also be seen in this animation:\n\nlibrary(gganimate)\nggplot(data = data_R_veh) +\n  geom_rect(aes(fill = \"Preceding Veh\", \n                xmin = preceding_local_y - preceding_length,\n                xmax = preceding_local_y,\n                ymin = preceding_local_x - (preceding_width/2),\n                ymax = preceding_local_x + (preceding_width/2))) +\n  geom_rect(aes(fill = \"Subject Veh\",\n                xmin = local_y - v_length,\n                xmax = local_y,\n                ymin = local_x - (v_width/2),\n                ymax = local_x + (v_width/2))) +\n  geom_hline(yintercept = 3.6, linetype = \"longdash\") +\n  coord_fixed(ratio=3.5) +\n  labs(fill = NULL) +\n  theme_minimal() + \n  theme(legend.position = \"none\") +\n  transition_reveal(time)"
  },
  {
    "objectID": "posts/transform/transform_py.html#load-parquet-file",
    "href": "posts/transform/transform_py.html#load-parquet-file",
    "title": "Transform Data with Python",
    "section": "Load parquet file",
    "text": "Load parquet file\nReading the parquet file requires the polars package:\n\nimport polars as pl\n\npath_to_first_period_file = \"data/i80_period1.parquet\"\ndata_py = pl.read_parquet(path_to_first_period_file)\n\ndata_py.head()\n\n\nshape: (5, 24)\n\n\n\nVehicle_ID\nFrame_ID\nTotal_Frames\nGlobal_Time\nLocal_X\nLocal_Y\nGlobal_X\nGlobal_Y\nv_length\nv_Width\nv_Class\nv_Vel\nv_Acc\nLane_ID\nO_Zone\nD_Zone\nInt_ID\nSection_ID\nDirection\nMovement\nPreceding\nFollowing\nSpace_Headway\nTime_Headway\n\n\ni32\ni32\ni32\ni64\nf64\nf64\nf64\nf64\nf64\nf64\ni32\nf64\nf64\ni32\ni32\ni32\ni32\ni32\ni32\ni32\ni32\ni32\nf64\nf64\n\n\n\n\n3027\n8493\n813\n1113433984200\n53.115\n363.266\n6.0428e6\n2.1334e6\n15.3\n7.4\n2\n21.46\n-8.14\n5\nnull\nnull\nnull\nnull\nnull\nnull\n3014\n3032\n64.23\n2.99\n\n\n3214\n9115\n708\n1113434046400\n67.931\n655.629\n6.0428e6\n2.1337e6\n13.8\n6.3\n2\n15.37\n11.2\n6\nnull\nnull\nnull\nnull\nnull\nnull\n3221\n3229\n31.71\n2.06\n\n\n3199\n9329\n575\n1113434067800\n17.026\n1237.592\n6.0427e6\n2.1343e6\n14.4\n5.9\n2\n39.3\n0.0\n2\nnull\nnull\nnull\nnull\nnull\nnull\n3188\n3206\n72.36\n1.84\n\n\n3159\n8919\n572\n1113434026800\n16.541\n306.905\n6.0428e6\n2.1334e6\n16.4\n5.9\n2\n14.71\n3.61\n2\nnull\nnull\nnull\nnull\nnull\nnull\n3152\n3171\n51.9\n3.53\n\n\n3314\n9324\n616\n1113434067300\n28.846\n65.807\n6.0429e6\n2.1331e6\n14.8\n6.4\n2\n36.24\n0.0\n3\nnull\nnull\nnull\nnull\nnull\nnull\n3301\n0\n103.26\n2.85"
  },
  {
    "objectID": "posts/transform/transform_py.html#how-to-create-variables-for-the-preceding-vehicle",
    "href": "posts/transform/transform_py.html#how-to-create-variables-for-the-preceding-vehicle",
    "title": "Transform Data with Python",
    "section": "How to create variables for the preceding vehicle?",
    "text": "How to create variables for the preceding vehicle?\nWe’d often need velocity, acceleration, and other variables for the preceding vehicle (vehicle in front of the subject vehicle). These variables can be useful in car-following modeling.\nIn this dataset, preceding vehicle variables do not exist as separate columns. The only relevant column is preceding which is the identifier of the preceding vehicle. But the data also contains the subject vehicle identifier vehicle_id, along with these variables:\n\nlocal_y: longitudinal position of the front end of the subject vehicle (feet)\n\nlocal_x: lateral position of the front end of the subject vehicle (feet)\n\nv_length and v_width are the length and width of the subject vehicle (feet)\n\nv_class is the class of the subject vehicle, i.e., 1 = motorcycle, 2 = car, and 3 = heavy vehicle (bus/truck)\n\nv_vel and v_acc are the velocity (ft/s) and acceleration (ft/s/s) of the subject vehicle\n\nOur goal now is to create new columns of the above variables for the preceding vehicle. To this end, we look for the value of preceding in the vehicle_id column at a given value of frame_id (identifier of time frame) and then grab the value of variable e.g., v_vel at that frame_id. In Python, we achieve this by joining a few columns of the dataset with the full dataset while using the columns vehicle_id and preceding for the join:\n\ndata_py = data_py.reset_index(drop=True)\n\n## Create new cols\n1data_py = data_py.merge(\n  data_py.loc[:, ['frame_id', 'vehicle_id', 'local_x', 'local_y', 'v_length',\n2            'v_width', 'v_class', 'v_vel', 'v_acc']] ,\n3              left_on = ['frame_id', 'preceding'],\n              right_on = ['frame_id', 'vehicle_id'],\n4              how = 'left',\n5              suffixes=['', '_preceding']\n              )\n6data_py = data_py.drop(['vehicle_id_preceding'], axis = 'columns')\n\ndata_py.head()\n\n\n1\n\nmerge is used for joining pandas dataframes.\n\n\n2\n\nThis is part of the data_py dataframe. It includes those variables of the subject vehicle that we want to create for the preceding vehicle.\n\n\n3\n\ndata_py is the “left” dataframe and data_py.loc[:, ['frame_id', 'vehicle_id', 'local_x', 'local_y', 'v_length', 'v_width', 'v_class', 'v_vel', 'v_acc']] is the “right” dataframe. At a given frame_id, ‘local_x’, ‘local_y’, ‘v_length’, ‘v_width’, ‘v_class’, ‘v_vel’, ‘v_acc’ are joined with data_py using the preceding and vehicle_id columns.\n\n\n4\n\nThe type of join is “left”.\n\n\n5\n\nA suffix _preceding is added to show that these variables are for the preceding vehicle.\n\n\n6\n\nThis operation created a redundant preceding vehicle ID that we drop here.\n\n\n\n\n\n\n\n\n\n\n\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\n...\ntime_headway\nactual_time\ntime\nlocal_x_preceding\nlocal_y_preceding\nv_length_preceding\nv_width_preceding\nv_class_preceding\nv_vel_preceding\nv_acc_preceding\n\n\n\n\n0\n1\n12\n884\n1113433136100\n16.884\n48.213\n6042842.116\n2133117.662\n14.3\n6.4\n...\n0.0\n2005-04-13 15:58:56.099999905-07:00\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1\n13\n884\n1113433136200\n16.938\n49.463\n6042842.012\n2133118.909\n14.3\n6.4\n...\n0.0\n2005-04-13 15:58:56.200000048-07:00\n0.1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n14\n884\n1113433136300\n16.991\n50.712\n6042841.908\n2133120.155\n14.3\n6.4\n...\n0.0\n2005-04-13 15:58:56.299999952-07:00\n0.2\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n1\n15\n884\n1113433136400\n17.045\n51.963\n6042841.805\n2133121.402\n14.3\n6.4\n...\n0.0\n2005-04-13 15:58:56.400000095-07:00\n0.3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n1\n16\n884\n1113433136500\n17.098\n53.213\n6042841.701\n2133122.649\n14.3\n6.4\n...\n0.0\n2005-04-13 15:58:56.500000-07:00\n0.4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 33 columns\n\n\n\nA NaN or null value indicates missing value. In this dataset, NaN / null indicates that the value is missing because there was no preceding vehicle observed. For vehicle_id 1 we can see this is true because the preceding value is 0.\nTo keep the column names consistent with the result in the same post with R code, we rename the preceding vehicle variables:\n\n1data_py = pl.from_pandas(data_py)\n\n2data_py = data_py.rename({\n    \"local_y_preceding\":\"preceding_local_y\", \n    \"v_length_preceding\":\"preceding_length\", \n    \"v_width_preceding\":\"preceding_width\", \n    \"v_class_preceding\":\"preceding_class\", \n    \"v_vel_preceding\":\"preceding_vel\", \n    \"v_acc_preceding\":\"preceding_acc\"\n    })\n    \ndata_py.columns\n\n\n1\n\nConvert the pandas dataframe to polars dataframe.\n\n2\n\nUse the polars.rename function to rename the columns.\n\n\n\n\n['vehicle_id',\n 'frame_id',\n 'total_frames',\n 'global_time',\n 'local_x',\n 'local_y',\n 'global_x',\n 'global_y',\n 'v_length',\n 'v_width',\n 'v_class',\n 'v_vel',\n 'v_acc',\n 'lane_id',\n 'o_zone',\n 'd_zone',\n 'int_id',\n 'section_id',\n 'direction',\n 'movement',\n 'preceding',\n 'following',\n 'space_headway',\n 'time_headway',\n 'actual_time',\n 'time',\n 'local_x_preceding',\n 'preceding_local_y',\n 'preceding_length',\n 'preceding_width',\n 'preceding_class',\n 'preceding_vel',\n 'preceding_acc']"
  },
  {
    "objectID": "posts/transform/transform_py.html#how-to-remove-undesired-columns",
    "href": "posts/transform/transform_py.html#how-to-remove-undesired-columns",
    "title": "Transform Data with Python",
    "section": "How to remove undesired columns?",
    "text": "How to remove undesired columns?\nThere are several variables in this dataset that we don’t need as they are completely devoid of any value. So we remove them:\n\ndata_py = data_py.drop([\"total_frames\", \"global_x\", \"global_y\", \"following\", \n              \"o_zone\", \"d_zone\", \"int_id\", \"section_id\", \"direction\", \n             \"movement\"])\n             \ndata_py.head()\n\n\nshape: (5, 23)\n\n\n\nvehicle_id\nframe_id\nglobal_time\nlocal_x\nlocal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nspace_headway\ntime_headway\nactual_time\ntime\nlocal_x_preceding\npreceding_local_y\npreceding_length\npreceding_width\npreceding_class\npreceding_vel\npreceding_acc\n\n\ni32\ni32\ni64\nf64\nf64\nf64\nf64\ni32\nf64\nf64\ni32\ni32\nf64\nf64\ndatetime[ns, America/Los_Angeles]\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n1\n12\n1113433136100\n16.884\n48.213\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.099999905 PDT\n0.0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n13\n1113433136200\n16.938\n49.463\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.200000048 PDT\n0.1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n14\n1113433136300\n16.991\n50.712\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.299999952 PDT\n0.2\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n15\n1113433136400\n17.045\n51.963\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.400000095 PDT\n0.3\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n16\n1113433136500\n17.098\n53.213\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.500 PDT\n0.4\nnull\nnull\nnull\nnull\nnull\nnull\nnull"
  },
  {
    "objectID": "posts/transform/transform_py.html#how-to-transform-multiple-columns",
    "href": "posts/transform/transform_py.html#how-to-transform-multiple-columns",
    "title": "Transform Data with Python",
    "section": "How to transform multiple columns?",
    "text": "How to transform multiple columns?\n\nMetric units\n\nAs discussed before, variables in this dataset have imperial units (feet, ft/s, etc.). You may want to transform the values of these variables to metric units. The conversion factor is 0.3048. Here, we utilize the polars.with_columns function to take all the desired columns (cols_to_convert_to_metric) and apply the conversion factor along with rounding to 2 decimal places:\n\n## convert to metric\ncols_to_convert_to_metric = ['local_x', 'local_y', 'v_length', 'v_width', \n        'v_vel', 'v_acc', 'space_headway', 'preceding_local_y',\n        'preceding_length', 'preceding_width', 'preceding_vel',\n       'preceding_acc']\n\ndata_py = data_py.with_columns((pl.col(cols_to_convert_to_metric) * .3048).round(2))\n\ndata_py.head()\n\n\nshape: (5, 23)\n\n\n\nvehicle_id\nframe_id\nglobal_time\nlocal_x\nlocal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nspace_headway\ntime_headway\nactual_time\ntime\nlocal_x_preceding\npreceding_local_y\npreceding_length\npreceding_width\npreceding_class\npreceding_vel\npreceding_acc\n\n\ni32\ni32\ni64\nf64\nf64\nf64\nf64\ni32\nf64\nf64\ni32\ni32\nf64\nf64\ndatetime[ns, America/Los_Angeles]\nf64\nf64\nf64\nf64\nf64\nf64\nf64\nf64\n\n\n\n\n1\n12\n1113433136100\n5.15\n14.7\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.099999905 PDT\n0.0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n13\n1113433136200\n5.16\n15.08\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.200000048 PDT\n0.1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n14\n1113433136300\n5.18\n15.46\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.299999952 PDT\n0.2\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n15\n1113433136400\n5.2\n15.84\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.400000095 PDT\n0.3\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n1\n16\n1113433136500\n5.21\n16.22\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13 15:58:56.500 PDT\n0.4\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\n\n\nConvert numbers/strings to categorical data type\nMoreover, we know that there are variables that should be treated as categorical (qualitative) rather than numbers or strings. For instance, lane_id has values 1-7 and we know that these are identifiers for lanes. Similarly, the class of a vehicle is encoded as 1, 2, and 3 but we know that these numbers do not have any quantitaive information, rather they are categories.\nIn polars, categorical data is encoded as polars.Categorical data type:\n\n## change the data type to categorical\ncols_to_convert_to_categorical = ['vehicle_id', 'v_class', 'lane_id', \n                             'preceding', 'preceding_class']\n1data_py = data_py.with_columns(pl.col(cols_to_convert_to_categorical).cast(pl.String).cast(pl.Categorical))\n\ndata_py.head()\n\n\n1\n\nColumns are first converted to string data type and then the strings are converted to categorical data type.\n\n\n\n\n\nshape: (5, 23)\n\n\n\nvehicle_id\nframe_id\nglobal_time\nlocal_x\nlocal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nspace_headway\ntime_headway\nactual_time\ntime\nlocal_x_preceding\npreceding_local_y\npreceding_length\npreceding_width\npreceding_class\npreceding_vel\npreceding_acc\n\n\ncat\ni32\ni64\nf64\nf64\nf64\nf64\ncat\nf64\nf64\ncat\ncat\nf64\nf64\ndatetime[ns, America/Los_Angeles]\nf64\nf64\nf64\nf64\nf64\ncat\nf64\nf64\n\n\n\n\n\"1\"\n12\n1113433136100\n5.15\n14.7\n4.36\n1.95\n\"2\"\n3.81\n0.0\n\"2\"\n\"0\"\n0.0\n0.0\n2005-04-13 15:58:56.099999905 PDT\n0.0\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"1\"\n13\n1113433136200\n5.16\n15.08\n4.36\n1.95\n\"2\"\n3.81\n0.0\n\"2\"\n\"0\"\n0.0\n0.0\n2005-04-13 15:58:56.200000048 PDT\n0.1\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"1\"\n14\n1113433136300\n5.18\n15.46\n4.36\n1.95\n\"2\"\n3.81\n0.0\n\"2\"\n\"0\"\n0.0\n0.0\n2005-04-13 15:58:56.299999952 PDT\n0.2\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"1\"\n15\n1113433136400\n5.2\n15.84\n4.36\n1.95\n\"2\"\n3.81\n0.0\n\"2\"\n\"0\"\n0.0\n0.0\n2005-04-13 15:58:56.400000095 PDT\n0.3\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"1\"\n16\n1113433136500\n5.21\n16.22\n4.36\n1.95\n\"2\"\n3.81\n0.0\n\"2\"\n\"0\"\n0.0\n0.0\n2005-04-13 15:58:56.500 PDT\n0.4\nnull\nnull\nnull\nnull\nnull\nnull\nnull"
  },
  {
    "objectID": "posts/transform/transform_py.html#visualization-with-one-vehicle",
    "href": "posts/transform/transform_py.html#visualization-with-one-vehicle",
    "title": "Transform Data with Python",
    "section": "Visualization with one vehicle",
    "text": "Visualization with one vehicle\nCool! We are almost done with transforming our dataset. It is time to do some visualization. The last transformation we learn is to filter the data to keep only one vehicle:\n\ndata_py_veh = data_py.filter(pl.col('vehicle_id') == \"2\")\n\nAnd now we use ggplot2 to create a plot of velocity over time. Subject vehicle in blue and preceding vehicle in orange.\n\nfrom lets_plot import *\nLetsPlot.setup_html()\n(\nggplot(data = data_py_veh) +\\\n  geom_path(mapping = aes(x = 'time', y = 'v_vel'), color = 'blue') +\\\n  geom_path(mapping = aes(x = 'time', y = 'preceding_vel'), color = 'orange') +\\\n  labs(x = \"Time (s)\", y = \"Velocity (m/s)\",\n       title = \"Velocity of vehicle # 2 and its preceding vehicle\") +\\\n  theme_minimal()\n)"
  },
  {
    "objectID": "posts/transform/transform_jl.html",
    "href": "posts/transform/transform_jl.html",
    "title": "Transform Data with Julia",
    "section": "",
    "text": "Note\n\n\n\nThis is the second post in the NGSIM data analysis series. Previous post:\n\nImport data\nIn the previous post, we partitioned the Interstate 80 (I80) vehicle trajectories data by time and then saved it on disk:\nWe now make use of the parquet file in the period=first directory for learning to transform data. Since this file is part of partitioned data, I saved it as a separate parquet file (i80_period1.parquet) in a different location."
  },
  {
    "objectID": "posts/transform/transform_jl.html#load-parquet-file",
    "href": "posts/transform/transform_jl.html#load-parquet-file",
    "title": "Transform Data with Julia",
    "section": "Load parquet file",
    "text": "Load parquet file\nReading the parquet file requires the Parquet2 package:\n\n# ] add Parquet2\nusing DataFrames\nusing Parquet2: Dataset\npath_to_first_period_file = \"data/i80_period1.parquet\"\ndata_jl = DataFrame(Dataset(path_to_first_period_file));\n\nfirst(data_jl, 5)\n\n5×24 DataFrame\n\n\n\nRow\nVehicle_ID\nFrame_ID\nTotal_Frames\nGlobal_Time\nLocal_X\nLocal_Y\nGlobal_X\nGlobal_Y\nv_length\nv_Width\nv_Class\nv_Vel\nv_Acc\nLane_ID\nO_Zone\nD_Zone\nInt_ID\nSection_ID\nDirection\nMovement\nPreceding\nFollowing\nSpace_Headway\nTime_Headway\n\n\n\nInt32?\nInt32?\nInt32?\nInt64?\nFloat64?\nFloat64?\nFloat64?\nFloat64?\nFloat64?\nFloat64?\nInt32?\nFloat64?\nFloat64?\nInt32?\nInt32?\nInt32?\nInt32?\nInt32?\nInt32?\nInt32?\nInt32?\nInt32?\nFloat64?\nFloat64?\n\n\n\n\n1\n3027\n8493\n813\n1113433984200\n53.115\n363.266\n6.04284e6\n2.13343e6\n15.3\n7.4\n2\n21.46\n-8.14\n5\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n3014\n3032\n64.23\n2.99\n\n\n2\n3214\n9115\n708\n1113434046400\n67.931\n655.629\n6.04282e6\n2.13373e6\n13.8\n6.3\n2\n15.37\n11.2\n6\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n3221\n3229\n31.71\n2.06\n\n\n3\n3199\n9329\n575\n1113434067800\n17.026\n1237.59\n6.04268e6\n2.1343e6\n14.4\n5.9\n2\n39.3\n0.0\n2\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n3188\n3206\n72.36\n1.84\n\n\n4\n3159\n8919\n572\n1113434026800\n16.541\n306.905\n6.04281e6\n2.13337e6\n16.4\n5.9\n2\n14.71\n3.61\n2\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n3152\n3171\n51.9\n3.53\n\n\n5\n3314\n9324\n616\n1113434067300\n28.846\n65.807\n6.04285e6\n2.13314e6\n14.8\n6.4\n2\n36.24\n0.0\n3\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n3301\n0\n103.26\n2.85"
  },
  {
    "objectID": "posts/transform/transform_jl.html#clean-dataframe-names",
    "href": "posts/transform/transform_jl.html#clean-dataframe-names",
    "title": "Transform Data with Julia",
    "section": "Clean dataframe names",
    "text": "Clean dataframe names\nAs you can see above, the column names are in good shape i.e., without any spaces. However, it is easier typing lowercase letters than the sentence case. So, we use the clean_names macro from the TidierData package to make all column names lower case. If the column names have spaces or periods in them, clean_names would replace them with underscores.\n\nusing TidierData\ndata_jl = @clean_names(data_jl)\n\n@glimpse(data_jl)\n\nRows: 1250932\nColumns: 24\n.vehicle_id    Union{Missing, Int32}3027, 3214, 3199, 3159, 3314, 3128, 3031, 29\n.frame_id      Union{Missing, Int32}8493, 9115, 9329, 8919, 9324, 9052, 9030, 86\n.total_frames  Union{Missing, Int32}813, 708, 575, 572, 616, 603, 958, 987, 760,\n.global_time   Union{Missing, Int64}1113433984200, 1113434046400, 1113434067800,\n.local_x       Union{Missing, Float64}53.115, 67.931, 17.026, 16.541, 28.846, 17\n.local_y       Union{Missing, Float64}363.266, 655.629, 1237.592, 306.905, 65.80\n.global_x      Union{Missing, Float64}6.042839372e6, 6.042817933e6, 6.042683444e\n.global_y      Union{Missing, Float64}2.133434927e6, 2.133726884e6, 2.134296961e\n.v_length      Union{Missing, Float64}15.3, 13.8, 14.4, 16.4, 14.8, 16.8, 15.3, \n.v_width       Union{Missing, Float64}7.4, 6.3, 5.9, 5.9, 6.4, 8.5, 7.4, 5.8, 8.\n.v_class       Union{Missing, Int32}2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n.v_vel         Union{Missing, Float64}21.46, 15.37, 39.3, 14.71, 36.24, 35.69, 2\n.v_acc         Union{Missing, Float64}-8.14, 11.2, 0.0, 3.61, 0.0, 11.2, 10.8, -\n.lane_id       Union{Missing, Int32}5, 6, 2, 2, 3, 2, 4, 4, 5, 5, 4, 6, 6, 2, 4,\n.o_zone        Union{Missing, Int32}missing, missing, missing, missing, missing,\n.d_zone        Union{Missing, Int32}missing, missing, missing, missing, missing,\n.int_id        Union{Missing, Int32}missing, missing, missing, missing, missing,\n.section_id    Union{Missing, Int32}missing, missing, missing, missing, missing,\n.direction     Union{Missing, Int32}missing, missing, missing, missing, missing,\n.movement      Union{Missing, Int32}missing, missing, missing, missing, missing,\n.preceding     Union{Missing, Int32}3014, 3221, 3188, 3152, 3301, 3125, 0, 2973,\n.following     Union{Missing, Int32}3032, 3229, 3206, 3171, 0, 3132, 3032, 2987,\n.space_headway Union{Missing, Float64}64.23, 31.71, 72.36, 51.9, 103.26, 90.81, \n.time_headway  Union{Missing, Float64}2.99, 2.06, 1.84, 3.53, 2.85, 2.54, 0.0, 3\n\n\nThe @glimpse macro shows that all variable names are now in lower case now. But variables have the Missing type common. This is perhaps because some of the columns have missing values. Let’s look at 2 variables:\n\ncount(x -&gt; ismissing(x), data_jl.frame_id)\n\n0\n\n\n\ncount(x -&gt; ismissing(x), data_jl.o_zone)\n\n1250932\n\n\nWe therefore remove all the columns that have missing values (completely missing!). Even after that, one of the type of the remaining variables is Missing. So, we replace missing values with zero just to change the type:\n\ndata_jl = @select(data_jl, Not(:o_zone, :d_zone, :int_id, :section_id, :direction, :movement))\nfor col in names(data_jl)\n    data_jl[!, col] .= coalesce.(data_jl[!, col], 0)\nend"
  },
  {
    "objectID": "posts/transform/transform_jl.html#how-to-create-a-time-column",
    "href": "posts/transform/transform_jl.html#how-to-create-a-time-column",
    "title": "Transform Data with Julia",
    "section": "How to create a time column?",
    "text": "How to create a time column?\nSince vehicle trajectories change over time, it is nice to see these changes over different time periods. However, the gloabl_time column in this dataset contains integers rather than the actual time. So, we create a new column called actual_time by dividing the global_time by 1000 and converting it to a datetime object.\nIn Julia, this can be done via Dates package. The integer to datetime data conversion will report time in UTC. But the data were collected in Los Angeles, so we want to specify the America/Los_Angeles time zone. Thus, we subtract 7 hours as UTC is 7 hours ahead of PDT:\n\nusing Dates\n\ndata_jl.actual_time = DateTime.(Dates.unix2datetime.(data_jl.global_time ./ 1000))\ndata_jl.actual_time = data_jl.actual_time .- Hour(7)\n\nfirst(data_jl, 5)\n\n5×19 DataFrame\n\n\n\nRow\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nfollowing\nspace_headway\ntime_headway\nactual_time\n\n\n\nInt32\nInt32\nInt32\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nInt32\nFloat64\nFloat64\nInt32\nInt32\nInt32\nFloat64\nFloat64\nDateTime\n\n\n\n\n1\n3027\n8493\n813\n1113433984200\n53.115\n363.266\n6.04284e6\n2.13343e6\n15.3\n7.4\n2\n21.46\n-8.14\n5\n3014\n3032\n64.23\n2.99\n2005-04-13T16:13:04.200\n\n\n2\n3214\n9115\n708\n1113434046400\n67.931\n655.629\n6.04282e6\n2.13373e6\n13.8\n6.3\n2\n15.37\n11.2\n6\n3221\n3229\n31.71\n2.06\n2005-04-13T16:14:06.400\n\n\n3\n3199\n9329\n575\n1113434067800\n17.026\n1237.59\n6.04268e6\n2.1343e6\n14.4\n5.9\n2\n39.3\n0.0\n2\n3188\n3206\n72.36\n1.84\n2005-04-13T16:14:27.800\n\n\n4\n3159\n8919\n572\n1113434026800\n16.541\n306.905\n6.04281e6\n2.13337e6\n16.4\n5.9\n2\n14.71\n3.61\n2\n3152\n3171\n51.9\n3.53\n2005-04-13T16:13:46.800\n\n\n5\n3314\n9324\n616\n1113434067300\n28.846\n65.807\n6.04285e6\n2.13314e6\n14.8\n6.4\n2\n36.24\n0.0\n3\n3301\n0\n103.26\n2.85\n2005-04-13T16:14:27.300\n\n\n\n\n\n\nNote that the data is not in the correct order. The vehicle_ids in the first two rows are 3027 and 3214. However, we know that the same vehicle was observed for several seconds. This means that we should see a given vehicle_id repeated over multiple rows consecutively. We therefore sort by vehicle_id and frame_id:\n\n## First: Sort by Vehicle ID and Time\ndata_jl = @arrange(data_jl, vehicle_id, frame_id)\nfirst(data_jl, 5)\n\n5×19 DataFrame\n\n\n\nRow\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nfollowing\nspace_headway\ntime_headway\nactual_time\n\n\n\nInt32\nInt32\nInt32\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nInt32\nFloat64\nFloat64\nInt32\nInt32\nInt32\nFloat64\nFloat64\nDateTime\n\n\n\n\n1\n1\n12\n884\n1113433136100\n16.884\n48.213\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.100\n\n\n2\n1\n13\n884\n1113433136200\n16.938\n49.463\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.200\n\n\n3\n1\n14\n884\n1113433136300\n16.991\n50.712\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.300\n\n\n4\n1\n15\n884\n1113433136400\n17.045\n51.963\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.400\n\n\n5\n1\n16\n884\n1113433136500\n17.098\n53.213\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.500\n\n\n\n\n\n\nWhen we want to compare several vehicle trajectories, e.g., how their speeds change over time regardless of when they were observed, we’d want a common time scale. The NGSIM documentation describes that vehicles were observed at a resolution of 0.1 seconds. So, we can create atime variable for each vehicle that starts at 0 and ends at (n-1)/10 where n = number of rows for which a vehicle_id is repeated:\n\ndata_jl = @chain data_jl begin\n1    @group_by(vehicle_id)\n2    @mutate(time = (0:(first(n()) - 1))/10)\n3    @ungroup()\nend;\n\n\n1\n\nGroup by vehicle_id so that time is calculated for each vehicle separately.\n\n\n2\n\nn() gives the group size.\n\n\n3\n\nDon’t forget to ungroup."
  },
  {
    "objectID": "posts/transform/transform_jl.html#how-to-create-variables-for-the-preceding-vehicle",
    "href": "posts/transform/transform_jl.html#how-to-create-variables-for-the-preceding-vehicle",
    "title": "Transform Data with Julia",
    "section": "How to create variables for the preceding vehicle?",
    "text": "How to create variables for the preceding vehicle?\nWe’d often need velocity, acceleration, and other variables for the preceding vehicle (vehicle in front of the subject vehicle). These variables can be useful in car-following modeling.\nIn this dataset, preceding vehicle variables do not exist as separate columns. The only relevant column is preceding which is the identifier of the preceding vehicle. But the data also contains the subject vehicle identifier vehicle_id, along with these variables:\n\nlocal_y: longitudinal position of the front end of the subject vehicle (feet)\n\nlocal_x: lateral position of the front end of the subject vehicle (feet)\n\nv_length and v_width are the length and width of the subject vehicle (feet)\n\nv_class is the class of the subject vehicle, i.e., 1 = motorcycle, 2 = car, and 3 = heavy vehicle (bus/truck)\n\nv_vel and v_acc are the velocity (ft/s) and acceleration (ft/s/s) of the subject vehicle\n\nOur goal now is to create new columns of the above variables for the preceding vehicle. To this end, we look for the value of preceding in the vehicle_id column at a given value of frame_id (identifier of time frame) and then grab the value of variable e.g., v_vel at that frame_id. In Julia, we achieve this by joining a few columns of the dataset with the full dataset while using the columns vehicle_id and preceding for the join:\n\n# Join\ndata_jl = leftjoin(\n           data_jl,\n           data_jl[:, [:frame_id, :vehicle_id, :local_y, :v_length, :v_width, :v_class, :v_vel, :v_acc]],\n           on = [:frame_id =&gt; :frame_id, :preceding =&gt; :vehicle_id],\n           makeunique = true, \n           renamecols = \"\" =&gt; \"_preceding\"\n       )\n\n# Arrange again\ndata_jl = @arrange(data_jl, vehicle_id, frame_id)\n\n\n# Rename columns to match with naming in R and Python posts\ndata_jl = @chain data_jl begin\n    @rename(preceding_local_y = local_y_preceding,\n            preceding_length =  v_length_preceding,\n            preceding_width = v_width_preceding,\n            preceding_class = v_class_preceding,\n            preceding_vel = v_vel_preceding,\n            preceding_acc = v_acc_preceding)\nend\n\nfirst(data_jl, 5)\n\n5×26 DataFrame\n\n\n\nRow\nvehicle_id\nframe_id\ntotal_frames\nglobal_time\nlocal_x\nlocal_y\nglobal_x\nglobal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nfollowing\nspace_headway\ntime_headway\nactual_time\ntime\npreceding_local_y\npreceding_length\npreceding_width\npreceding_class\npreceding_vel\npreceding_acc\n\n\n\nInt32\nInt32\nInt32\nInt64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nInt32\nFloat64\nFloat64\nInt32\nInt32\nInt32\nFloat64\nFloat64\nDateTime\nFloat64\nFloat64?\nFloat64?\nFloat64?\nInt32?\nFloat64?\nFloat64?\n\n\n\n\n1\n1\n12\n884\n1113433136100\n16.884\n48.213\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.100\n0.0\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n2\n1\n13\n884\n1113433136200\n16.938\n49.463\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.200\n0.1\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n3\n1\n14\n884\n1113433136300\n16.991\n50.712\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.300\n0.2\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n4\n1\n15\n884\n1113433136400\n17.045\n51.963\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.400\n0.3\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n5\n1\n16\n884\n1113433136500\n17.098\n53.213\n6.04284e6\n2.13312e6\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0\n0.0\n0.0\n2005-04-13T15:58:56.500\n0.4\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n\n\n\n\nIn this dataset, missing indicates that the value is missing because there was no preceding vehicle observed. For vehicle_id 1 we can see this is true because the preceding value is 0."
  },
  {
    "objectID": "posts/transform/transform_jl.html#how-to-remove-undesired-columns",
    "href": "posts/transform/transform_jl.html#how-to-remove-undesired-columns",
    "title": "Transform Data with Julia",
    "section": "How to remove undesired columns?",
    "text": "How to remove undesired columns?\nThere are several variables in this dataset that we don’t need as they are completely devoid of any value. We have removed those variables already. We further remove variables that we don’t need for analysis:\n\ndata_jl = @select(data_jl, Not(:total_frames, starts_with(\"global\"), :following))\nfirst(data_jl, 5)\n\n5×21 DataFrame\n\n\n\nRow\nvehicle_id\nframe_id\nlocal_x\nlocal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nspace_headway\ntime_headway\nactual_time\ntime\npreceding_local_y\npreceding_length\npreceding_width\npreceding_class\npreceding_vel\npreceding_acc\n\n\n\nInt32\nInt32\nFloat64\nFloat64\nFloat64\nFloat64\nInt32\nFloat64\nFloat64\nInt32\nInt32\nFloat64\nFloat64\nDateTime\nFloat64\nFloat64?\nFloat64?\nFloat64?\nInt32?\nFloat64?\nFloat64?\n\n\n\n\n1\n1\n12\n16.884\n48.213\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.100\n0.0\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n2\n1\n13\n16.938\n49.463\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.200\n0.1\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n3\n1\n14\n16.991\n50.712\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.300\n0.2\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n4\n1\n15\n17.045\n51.963\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.400\n0.3\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n5\n1\n16\n17.098\n53.213\n14.3\n6.4\n2\n12.5\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.500\n0.4\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing"
  },
  {
    "objectID": "posts/transform/transform_jl.html#how-to-transform-multiple-columns",
    "href": "posts/transform/transform_jl.html#how-to-transform-multiple-columns",
    "title": "Transform Data with Julia",
    "section": "How to transform multiple columns?",
    "text": "How to transform multiple columns?\n\nMetric units\n\nAs discussed before, variables in this dataset have imperial units (feet, ft/s, etc.). You may want to transform the values of these variables to metric units. The conversion factor is 0.3048. Here, we write a function to take a column and apply the conversion factor along with rounding to 2 decimal places:\n\n## metric units\nfunction convert_and_round(x)\n    return round(x * 0.3048, digits=2)\nend\n\ncols_to_mutate = [\"local_x\", \"local_y\", \"v_length\", \"v_width\", \n                 \"v_vel\", \"v_acc\", \"space_headway\",\n                 \"preceding_local_y\", \"preceding_length\", \"preceding_width\",\n                 \"preceding_vel\", \"preceding_acc\"]\n\nfor col in cols_to_mutate\n    data_jl[!, col] .= convert_and_round.(data_jl[!, col])\nend\n\nfirst(data_jl, 5)\n\n5×21 DataFrame\n\n\n\nRow\nvehicle_id\nframe_id\nlocal_x\nlocal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nspace_headway\ntime_headway\nactual_time\ntime\npreceding_local_y\npreceding_length\npreceding_width\npreceding_class\npreceding_vel\npreceding_acc\n\n\n\nInt32\nInt32\nFloat64\nFloat64\nFloat64\nFloat64\nInt32\nFloat64\nFloat64\nInt32\nInt32\nFloat64\nFloat64\nDateTime\nFloat64\nFloat64?\nFloat64?\nFloat64?\nInt32?\nFloat64?\nFloat64?\n\n\n\n\n1\n1\n12\n5.15\n14.7\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.100\n0.0\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n2\n1\n13\n5.16\n15.08\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.200\n0.1\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n3\n1\n14\n5.18\n15.46\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.300\n0.2\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n4\n1\n15\n5.2\n15.84\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.400\n0.3\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n5\n1\n16\n5.21\n16.22\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.500\n0.4\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n\n\n\n\n\n\nConvert numbers to string data type\nMoreover, we know that there are variables that should be treated as categorical (qualitative) rather than numbers. For instance, lane_id has values 1-7 and we know that these are identifiers for lanes. Similarly, the class of a vehicle is encoded as 1, 2, and 3 but we know that these numbers do not have any quantitaive information, rather they are categories.\nWe use the string function to convert numbers to string data type:\n\ndata_jl[!,:vehicle_id] = string.(data_jl[!,:vehicle_id])\ndata_jl[!,:v_class] = string.(data_jl[!,:v_class])\ndata_jl[!,:lane_id] = string.(data_jl[!,:lane_id])\ndata_jl[!,:preceding] = string.(data_jl[!,:preceding])\ndata_jl[!,:preceding_class] = string.(data_jl[!,:preceding_class])\n\nfirst(data_jl, 5)\n\n5×21 DataFrame\n\n\n\nRow\nvehicle_id\nframe_id\nlocal_x\nlocal_y\nv_length\nv_width\nv_class\nv_vel\nv_acc\nlane_id\npreceding\nspace_headway\ntime_headway\nactual_time\ntime\npreceding_local_y\npreceding_length\npreceding_width\npreceding_class\npreceding_vel\npreceding_acc\n\n\n\nString\nInt32\nFloat64\nFloat64\nFloat64\nFloat64\nString\nFloat64\nFloat64\nString\nString\nFloat64\nFloat64\nDateTime\nFloat64\nFloat64?\nFloat64?\nFloat64?\nString\nFloat64?\nFloat64?\n\n\n\n\n1\n1\n12\n5.15\n14.7\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.100\n0.0\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n2\n1\n13\n5.16\n15.08\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.200\n0.1\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n3\n1\n14\n5.18\n15.46\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.300\n0.2\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n4\n1\n15\n5.2\n15.84\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.400\n0.3\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing\n\n\n5\n1\n16\n5.21\n16.22\n4.36\n1.95\n2\n3.81\n0.0\n2\n0\n0.0\n0.0\n2005-04-13T15:58:56.500\n0.4\nmissing\nmissing\nmissing\nmissing\nmissing\nmissing"
  },
  {
    "objectID": "posts/transform/transform_jl.html#visualization-with-one-vehicle",
    "href": "posts/transform/transform_jl.html#visualization-with-one-vehicle",
    "title": "Transform Data with Julia",
    "section": "Visualization with one vehicle",
    "text": "Visualization with one vehicle\nCool! We are almost done with transforming our dataset. It is time to do some visualization. The last transformation we learn is to filter the data to keep only one vehicle:\n\ndata_jl_veh = @filter(data_jl, vehicle_id == \"2\");\n\nAnd now we use TidierPlots to create a plot of velocity over time. Subject vehicle in blue and preceding vehicle in orange.\n\nusing TidierPlots\nggplot(data = data_jl_veh) +\n  geom_path(aes(x = \"time\", y = \"v_vel\"), color = \"blue\") +\n  geom_path(aes(x = \"time\", y = \"preceding_vel\"), color = \"orange\") +\n  labs(x = \"Time (s)\", y = \"Velocity (m/s)\",\n       title = \"Velocity of vehicle # 2 and its preceding vehicle\") +\n  theme_minimal()\n\nheight: 400\nx: Time (s)\ntitle: Velocity of vehicle # 2 and its preceding vehicle\nwidth: 600\ny: Velocity (m/s)\n\ngeom_path\ndata: inherits from plot\nx: time \ny: v_vel \n\ngeom_path\ndata: inherits from plot\nx: time \ny: preceding_vel \n\n\n\n\n\n\n\nggplot options\ndata: A DataFrame (415 rows, 21 columns)\n\n\n\n\nAs you see, the lead vehicle speed is not seen after about 17 seconds. This is because the lead vehicle changed lanes."
  }
]