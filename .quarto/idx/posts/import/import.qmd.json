{"title":"Import Data with R","markdown":{"yaml":{"title":"Import Data with R","date":"2024-01-01","categories":["import","time-space"],"image":"trajectories.gif","code-annotations":"hover"},"headingText":"After completing this post, you will be able to:","containsRefs":false,"markdown":"\n\n::: {.callout-tip}\n\n* Programmatically download and save raw NGSIM data  \n* Partition the raw data by location and save as separate `parquet` files without loading them into memory  \n* Create this time-space diagram:  \n   ![](trajectories.gif){width=70%}\n    \nNote: The code in this post is derived from [Chapter 22 of R for Data Science book](https://r4ds.hadley.nz/arrow).  \n\n:::\n\n[All code in this post is written in `R` programming language.]{.aside}\n\n\n## Download raw data\n\nWe begin by downloading the NGSIM data from their website. Generally, you do this by clicking the download button on the data page. In R, you can download the data as follows. First, you create a `data` folder in your desired location:  \n\n```{r dowload1}\n#| eval: false\ndir.create(\"data\")\n```\n\nNext, utilize the `download.file` function to download the NGSIM data:\n\n```{r dowload2}\n#| eval: false\ndate_today <- format(Sys.Date(), \"%Y%m%d\")\ndata_url <- paste0(\"https://datahub.transportation.gov/api/views/8ect-6jqj/rows.csv?date=\", date_today, \"&accessType=DOWNLOAD\")\n\n# Download\ndownload.file(url = data_url, destfile = \"data/ngsim_data.csv\")\n```\n\nIn the code chunk above, `Sys.Date()` provides today's date which we name as `date_today`. Then `data_url` is the URL built with `date_today` as that is how the ITS hub provides access to the data. This is the URL that we then provide to the `download.file` function along with the location and name of the csv file.   \n\nThe time to download this 1.4 GB file depends on your internet speed. It took about 10 minutes on a 60 MB/s connection I tested.  \n\n![](ngsim_csv.PNG)  \n\n\n## Partition NGSIM data by location\n\nThe NGSIM data has millions of rows and has a disk size of 1.4 GB! You *can* load all the data in R using the awesome `data.table` package:  \n\n```{r loadAll}\n#| eval: false\nlibrary(data.table)\nngsim_data <- fread(\"data/ngsim_data.csv\")\n```\n\n[Note that R uses both the `<-` and `=` as assignment operators. But `<-` is used more frequently.]{.aside}\n\nLoading this data in R may be possible with good enough computer memory, but may not be a good idea due to the following reasons:  \n\n* Intensive calculations may slow down and even crash your R session when all the data is used simultaneously.  \n* You may be interested in analyzing only part of the data, e.g., only the Interstate-80 trajectories.  \n\n\nSo, we use the `arrow` package to partition the data by location and use tools to minimize loading large parts of data in memory (all data imported in R is available in computer memory).  \n\n### Open `NGSIM`\n\n![](https://media.giphy.com/media/3o6Mbp8RPCrhrrFB6M/giphy.gif)\n\n`arrow` has this `open_dataset` function that lets you peek inside the data without actually loading it into memory.  \n\n[Hover over the annotated line numbers to see the code description.]{.aside}\n\n```{r arrow1}\nlibrary(arrow)\nngsim_data <- open_dataset(\n  sources = \"data/ngsim_data.csv\", # <1>\n  col_types = schema(Location = string()), # <2>\n  format = \"csv\" # <3>\n)\n```\n1. Provide the location and name of the data file.  \n2. Optionally provide the column types. For example, read the `Location` column as a string type.  \n3. Specify the format of the input file.   \n\nThis does not read the entire dataset, but rather creates an `ArrowObject` that provides metadata:  \n\n```{r arrow2}\nngsim_data\n```\n\nHere you see several variables with their types. We can now use the `Location` variable to partition data.  \n\n### Partition by location and save\n\nNow we load the `dplyr` package to group the data by `Location` and then use `arrow` to save it.  \n\n```{r arrow3}\n#| eval: false\ndata_by_location_folder <- \"data/ngsim_location\" # <1>\n\nngsim_data |>\n  dplyr::group_by(Location) |> # <2>\n  write_dataset(path = data_by_location_folder, format = \"parquet\") # <3>\n```\n1. Path to the folder where you want to store files.  \n2. Group by the `Location` variable.  \n3. Save partitioned data in the specified location as a parquet file. Parquet files are column-based and are faster to read and write than csv files.  \n\n[The `|>` is a pipe operator in R. It means \"and then\". For example, take `ngsim_data` and then group it by `Location`.]{.aside}\n\nEach saved file is named as `part-0.parquet` in its own folder: \n\n![](ngsim_location.PNG)\n   \n   \n   \nThe beauty of the above code is that new files are created and saved without loading any data into memory. So, you don't need to wait to get to your desired data for analysis.   \n\n\nLet's see the size of each file:  \n\n```{r}\n#| echo: false\ndata_by_location_folder <- \"data/ngsim_location\"\n```\n\n```{r arrow4}\nlibrary(tibble)\ntibble(\n  files = list.files(data_by_location_folder, recursive = TRUE),\n  size_MB = file.size(file.path(data_by_location_folder, files)) / 1024^2\n)\n```\n\nThese are small datasets that most computers can easily deal with.  \n\n\n## Create a time-space diagram with Interstate-80 data\n\nAccording to the [official web-page](https://www.fhwa.dot.gov/publications/research/operations/06137/), Interstate-80 (I80 from now on) data consists of vehicle trajectories collected between 4 pm - 5:30 pm on April 13, 2005.   \n\nTo create a time-space diagram, we need variables for time (x-axis) and space (y-axis). `Local_Y` represents the longitudinal position of the front end of vehicles, so we can plot it on y-axis. However, there is only an interger encoded time variable in the data `Global_Time`. Therefore, the first step is to create a new column that contains the actual time.  \n\n### Open the I80 data and find the time range \n\nWe start by opening the I80 dataset:  \n\n```{r i801}\ni80 <- open_dataset(paste0(data_by_location_folder, \"/Location=i-80\"))\n\ni80\n```\n\nUsing the `lubridate` package, we create a new column `actual_time`:  \n\n```{r i802}\nlibrary(dplyr)\nlibrary(lubridate)\ntime_range <- i80 |>\n  select(Global_Time) |> # <1>\n  collect() |> # <2>\n  mutate(actual_time = as_datetime(Global_Time / 1000, # <3>\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |>\n  pull(actual_time) |> # <4>\n  range() # <5>\n```\n1. Select the `Global_Time` column without loading it.  \n2. Collect the selected data into memory.  \n3. Create the `actual_time` column by utilizing `lubridate::as_datetime`. Note that the appropriate timezone is provided.  \n4. Pull out the `actual_time` column as a vector. A vector in R is a collection of numbers.   \n5. Find the range (min. and max.) of the time.  \n\nLet's see the range:  \n\n```{r i803}\ntime_range\n```\n\nThis result indicates that the data was collected between 3:58 pm to 5:32 pm on April 13, 2005 which matches the description on the web-page.   \n\n### Partition the I80 data\n\nThe description further says:  \n\n> A total of 45 minutes of data are available in the full dataset, segmented into three 15-minute periods: 4:00 p.m. to 4:15 p.m.; 5:00 p.m. to 5:15 p.m.; and 5:15 p.m. to 5:30 p.m.  \n\nHowever, the `time_range` indicates that data is available for 90 minutes rather than 45 minutes. Here, we follow the description and partition the I80 data by the specified periods:  \n\n```{r i804}\n#| eval: false\n# Specify the time periods:\nfirst_period_starts <- time_range[1]\nfirst_period_ends <- as_datetime(\"2005-04-13 16:15:00\", tz = \"America/Los_Angeles\")\nsecond_period_starts <- as_datetime(\"2005-04-13 17:00:00\", tz = \"America/Los_Angeles\")\nsecond_period_ends <- as_datetime(\"2005-04-13 17:15:00\", tz = \"America/Los_Angeles\")\nthird_period_ends <- time_range[2]\n\n# Since Global_Time is an integer, convert the start and end vars to integers:\nfirst_period_starts <- as.numeric(first_period_starts) * 1000\nfirst_period_ends <- as.numeric(first_period_ends) * 1000\nsecond_period_starts <- as.numeric(second_period_starts) * 1000\nsecond_period_ends <- as.numeric(second_period_ends) * 1000\nthird_period_ends <- as.numeric(third_period_ends) * 1000\n\n# Create the period column\ni80 |>\n  mutate(period = case_when(\n    Global_Time >= first_period_starts & Global_Time <= first_period_ends ~ \"first\",\n    Global_Time >= second_period_starts & Global_Time <= second_period_ends ~ \"second\",\n    Global_Time > second_period_ends & Global_Time <= third_period_ends ~ \"third\"\n  )) |>\n  group_by(period) |>\n  write_dataset(path = \"data/I80\", format = \"parquet\")\n```\nThe code above uses `dplyr::case_when` inside a `mutate` statement to create a new column that indicates the time period based on the specified start & end of each time period. Note that we did not use the `actual_time` column here because it does not exist in the saved parquet files. This column was created on the fly when the `time_range` variable was created.    \n\n\nThis creates four, not three, files as expected:   \n\n![](i80_period.PNG)\n\n\n### Time-space diagram\n\nLet's create a time-space diagram of the first period in I80 dataset. We see that I80 has following lanes:  \n\n```{r i805}\nopen_dataset(\"data/I80\") |>\n  pull(Lane_ID, as_vector = TRUE) |>\n  unique()\n```\n\nFor our diagram, we limit the data to the first three lanes only:  \n\n```{r i806}\n#| eval: false\ni80_filtered <- open_dataset(\"data/I80\") |> # <1>\n  filter(\n    period %in% c(\"first\"), # <2>\n    Lane_ID %in% c(1, 2, 3)\n  ) |>\n  collect() |>\n  mutate(actual_time = as_datetime(Global_Time / 1000,\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |>\n  arrange(Vehicle_ID, actual_time)  # <3>\n```\n1. Open partitioned I80 dataset.  \n2. Filter the data to contain trajectories in lanes 1, 2, and 3 during the first period only.  \n3. Sort by `Vehicle_ID` and `actual_time`.    \n\n\nNow, we use the `ggplot2` package to create the diagram:   \n\n```{r i807}\n#| eval: false\nlibrary(ggplot2)\ntime_space_diagram_i80 <- i80_filtered |>\n  ggplot() + # <1>\n  geom_path( # <2>\n    aes(\n      x = actual_time, # <3>\n      y = Local_Y,     # <4>\n      color = v_Vel,   # <5>\n      group = Vehicle_ID # <6>\n    ),\n    alpha = 0.5         # <7>\n  ) +\n  scale_color_gradient(low = \"red\", high = \"green\") + # <8>\n  facet_grid(Lane_ID ~ ., labeller = \"label_both\") +  # <9>\n  labs(                                               # <10>\n    x = \"Time (HH:MM)\",\n    y = \"Longitudinal position\",\n    color = \"Speed (m/s)\"\n  ) +\n  theme_minimal()                                    # <11>\n\ntime_space_diagram_i80\n```\n1. Start by calling the `ggplot` function.  \n2. Use `geom_path` to create continuous lines.  \n3. Time on x-axis.  \n4. Longitudinal position (feet) on y-axis.  \n5. Colour by vehicle speed.  \n6. Create a separate line for each vehicle by specifying `group` as `Vehicle_ID`.  7. Make the lines 50% transparent.  \n8. Use red and green color scale.  \n9. Create small but connected plots (small multiples) for each lane.  \n10. Add labels to axes and colour legend.  \n11. Use the minimal theme to declutter the plot.  \n\n\n![](time_space_diagram.png)\n\n`ggplot2` has this handy function `ggsave` to save the plotted image to disk:  \n\n```{r i808}\n#| eval: false\nggsave(time_space_diagram_i80,           # <1>\n       path = \"time_space_diagram.png\",  # <2>\n       width = 11,                       # <3>\n       height = 8,                       # <4>\n       units = \"in\",                     # <5>\n       dpi = 30)                        # <6>\n```\n1. Specify the plot that you want to save.  \n2. Provide the full path with file name where you want to save the plotted image.  \n3. Specify the width of plotted image.  \n4. Specify the height of plotted image.  \n5. Specify the units of width and height. `\"in\"` means inches.  \n6. Specify the resolution of the image. Higher resolution makes crisper images but takes longer to plot than lower resolution.  \n\nAnd we are done!  Believe it or not, saving this plot took longer than any other step in this post.","srcMarkdownNoYaml":"\n\n::: {.callout-tip}\n## After completing this post, you will be able to:\n\n* Programmatically download and save raw NGSIM data  \n* Partition the raw data by location and save as separate `parquet` files without loading them into memory  \n* Create this time-space diagram:  \n   ![](trajectories.gif){width=70%}\n    \nNote: The code in this post is derived from [Chapter 22 of R for Data Science book](https://r4ds.hadley.nz/arrow).  \n\n:::\n\n[All code in this post is written in `R` programming language.]{.aside}\n\n\n## Download raw data\n\nWe begin by downloading the NGSIM data from their website. Generally, you do this by clicking the download button on the data page. In R, you can download the data as follows. First, you create a `data` folder in your desired location:  \n\n```{r dowload1}\n#| eval: false\ndir.create(\"data\")\n```\n\nNext, utilize the `download.file` function to download the NGSIM data:\n\n```{r dowload2}\n#| eval: false\ndate_today <- format(Sys.Date(), \"%Y%m%d\")\ndata_url <- paste0(\"https://datahub.transportation.gov/api/views/8ect-6jqj/rows.csv?date=\", date_today, \"&accessType=DOWNLOAD\")\n\n# Download\ndownload.file(url = data_url, destfile = \"data/ngsim_data.csv\")\n```\n\nIn the code chunk above, `Sys.Date()` provides today's date which we name as `date_today`. Then `data_url` is the URL built with `date_today` as that is how the ITS hub provides access to the data. This is the URL that we then provide to the `download.file` function along with the location and name of the csv file.   \n\nThe time to download this 1.4 GB file depends on your internet speed. It took about 10 minutes on a 60 MB/s connection I tested.  \n\n![](ngsim_csv.PNG)  \n\n\n## Partition NGSIM data by location\n\nThe NGSIM data has millions of rows and has a disk size of 1.4 GB! You *can* load all the data in R using the awesome `data.table` package:  \n\n```{r loadAll}\n#| eval: false\nlibrary(data.table)\nngsim_data <- fread(\"data/ngsim_data.csv\")\n```\n\n[Note that R uses both the `<-` and `=` as assignment operators. But `<-` is used more frequently.]{.aside}\n\nLoading this data in R may be possible with good enough computer memory, but may not be a good idea due to the following reasons:  \n\n* Intensive calculations may slow down and even crash your R session when all the data is used simultaneously.  \n* You may be interested in analyzing only part of the data, e.g., only the Interstate-80 trajectories.  \n\n\nSo, we use the `arrow` package to partition the data by location and use tools to minimize loading large parts of data in memory (all data imported in R is available in computer memory).  \n\n### Open `NGSIM`\n\n![](https://media.giphy.com/media/3o6Mbp8RPCrhrrFB6M/giphy.gif)\n\n`arrow` has this `open_dataset` function that lets you peek inside the data without actually loading it into memory.  \n\n[Hover over the annotated line numbers to see the code description.]{.aside}\n\n```{r arrow1}\nlibrary(arrow)\nngsim_data <- open_dataset(\n  sources = \"data/ngsim_data.csv\", # <1>\n  col_types = schema(Location = string()), # <2>\n  format = \"csv\" # <3>\n)\n```\n1. Provide the location and name of the data file.  \n2. Optionally provide the column types. For example, read the `Location` column as a string type.  \n3. Specify the format of the input file.   \n\nThis does not read the entire dataset, but rather creates an `ArrowObject` that provides metadata:  \n\n```{r arrow2}\nngsim_data\n```\n\nHere you see several variables with their types. We can now use the `Location` variable to partition data.  \n\n### Partition by location and save\n\nNow we load the `dplyr` package to group the data by `Location` and then use `arrow` to save it.  \n\n```{r arrow3}\n#| eval: false\ndata_by_location_folder <- \"data/ngsim_location\" # <1>\n\nngsim_data |>\n  dplyr::group_by(Location) |> # <2>\n  write_dataset(path = data_by_location_folder, format = \"parquet\") # <3>\n```\n1. Path to the folder where you want to store files.  \n2. Group by the `Location` variable.  \n3. Save partitioned data in the specified location as a parquet file. Parquet files are column-based and are faster to read and write than csv files.  \n\n[The `|>` is a pipe operator in R. It means \"and then\". For example, take `ngsim_data` and then group it by `Location`.]{.aside}\n\nEach saved file is named as `part-0.parquet` in its own folder: \n\n![](ngsim_location.PNG)\n   \n   \n   \nThe beauty of the above code is that new files are created and saved without loading any data into memory. So, you don't need to wait to get to your desired data for analysis.   \n\n\nLet's see the size of each file:  \n\n```{r}\n#| echo: false\ndata_by_location_folder <- \"data/ngsim_location\"\n```\n\n```{r arrow4}\nlibrary(tibble)\ntibble(\n  files = list.files(data_by_location_folder, recursive = TRUE),\n  size_MB = file.size(file.path(data_by_location_folder, files)) / 1024^2\n)\n```\n\nThese are small datasets that most computers can easily deal with.  \n\n\n## Create a time-space diagram with Interstate-80 data\n\nAccording to the [official web-page](https://www.fhwa.dot.gov/publications/research/operations/06137/), Interstate-80 (I80 from now on) data consists of vehicle trajectories collected between 4 pm - 5:30 pm on April 13, 2005.   \n\nTo create a time-space diagram, we need variables for time (x-axis) and space (y-axis). `Local_Y` represents the longitudinal position of the front end of vehicles, so we can plot it on y-axis. However, there is only an interger encoded time variable in the data `Global_Time`. Therefore, the first step is to create a new column that contains the actual time.  \n\n### Open the I80 data and find the time range \n\nWe start by opening the I80 dataset:  \n\n```{r i801}\ni80 <- open_dataset(paste0(data_by_location_folder, \"/Location=i-80\"))\n\ni80\n```\n\nUsing the `lubridate` package, we create a new column `actual_time`:  \n\n```{r i802}\nlibrary(dplyr)\nlibrary(lubridate)\ntime_range <- i80 |>\n  select(Global_Time) |> # <1>\n  collect() |> # <2>\n  mutate(actual_time = as_datetime(Global_Time / 1000, # <3>\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |>\n  pull(actual_time) |> # <4>\n  range() # <5>\n```\n1. Select the `Global_Time` column without loading it.  \n2. Collect the selected data into memory.  \n3. Create the `actual_time` column by utilizing `lubridate::as_datetime`. Note that the appropriate timezone is provided.  \n4. Pull out the `actual_time` column as a vector. A vector in R is a collection of numbers.   \n5. Find the range (min. and max.) of the time.  \n\nLet's see the range:  \n\n```{r i803}\ntime_range\n```\n\nThis result indicates that the data was collected between 3:58 pm to 5:32 pm on April 13, 2005 which matches the description on the web-page.   \n\n### Partition the I80 data\n\nThe description further says:  \n\n> A total of 45 minutes of data are available in the full dataset, segmented into three 15-minute periods: 4:00 p.m. to 4:15 p.m.; 5:00 p.m. to 5:15 p.m.; and 5:15 p.m. to 5:30 p.m.  \n\nHowever, the `time_range` indicates that data is available for 90 minutes rather than 45 minutes. Here, we follow the description and partition the I80 data by the specified periods:  \n\n```{r i804}\n#| eval: false\n# Specify the time periods:\nfirst_period_starts <- time_range[1]\nfirst_period_ends <- as_datetime(\"2005-04-13 16:15:00\", tz = \"America/Los_Angeles\")\nsecond_period_starts <- as_datetime(\"2005-04-13 17:00:00\", tz = \"America/Los_Angeles\")\nsecond_period_ends <- as_datetime(\"2005-04-13 17:15:00\", tz = \"America/Los_Angeles\")\nthird_period_ends <- time_range[2]\n\n# Since Global_Time is an integer, convert the start and end vars to integers:\nfirst_period_starts <- as.numeric(first_period_starts) * 1000\nfirst_period_ends <- as.numeric(first_period_ends) * 1000\nsecond_period_starts <- as.numeric(second_period_starts) * 1000\nsecond_period_ends <- as.numeric(second_period_ends) * 1000\nthird_period_ends <- as.numeric(third_period_ends) * 1000\n\n# Create the period column\ni80 |>\n  mutate(period = case_when(\n    Global_Time >= first_period_starts & Global_Time <= first_period_ends ~ \"first\",\n    Global_Time >= second_period_starts & Global_Time <= second_period_ends ~ \"second\",\n    Global_Time > second_period_ends & Global_Time <= third_period_ends ~ \"third\"\n  )) |>\n  group_by(period) |>\n  write_dataset(path = \"data/I80\", format = \"parquet\")\n```\nThe code above uses `dplyr::case_when` inside a `mutate` statement to create a new column that indicates the time period based on the specified start & end of each time period. Note that we did not use the `actual_time` column here because it does not exist in the saved parquet files. This column was created on the fly when the `time_range` variable was created.    \n\n\nThis creates four, not three, files as expected:   \n\n![](i80_period.PNG)\n\n\n### Time-space diagram\n\nLet's create a time-space diagram of the first period in I80 dataset. We see that I80 has following lanes:  \n\n```{r i805}\nopen_dataset(\"data/I80\") |>\n  pull(Lane_ID, as_vector = TRUE) |>\n  unique()\n```\n\nFor our diagram, we limit the data to the first three lanes only:  \n\n```{r i806}\n#| eval: false\ni80_filtered <- open_dataset(\"data/I80\") |> # <1>\n  filter(\n    period %in% c(\"first\"), # <2>\n    Lane_ID %in% c(1, 2, 3)\n  ) |>\n  collect() |>\n  mutate(actual_time = as_datetime(Global_Time / 1000,\n    origin = \"1970-01-01\",\n    tz = \"America/Los_Angeles\"\n  )) |>\n  arrange(Vehicle_ID, actual_time)  # <3>\n```\n1. Open partitioned I80 dataset.  \n2. Filter the data to contain trajectories in lanes 1, 2, and 3 during the first period only.  \n3. Sort by `Vehicle_ID` and `actual_time`.    \n\n\nNow, we use the `ggplot2` package to create the diagram:   \n\n```{r i807}\n#| eval: false\nlibrary(ggplot2)\ntime_space_diagram_i80 <- i80_filtered |>\n  ggplot() + # <1>\n  geom_path( # <2>\n    aes(\n      x = actual_time, # <3>\n      y = Local_Y,     # <4>\n      color = v_Vel,   # <5>\n      group = Vehicle_ID # <6>\n    ),\n    alpha = 0.5         # <7>\n  ) +\n  scale_color_gradient(low = \"red\", high = \"green\") + # <8>\n  facet_grid(Lane_ID ~ ., labeller = \"label_both\") +  # <9>\n  labs(                                               # <10>\n    x = \"Time (HH:MM)\",\n    y = \"Longitudinal position\",\n    color = \"Speed (m/s)\"\n  ) +\n  theme_minimal()                                    # <11>\n\ntime_space_diagram_i80\n```\n1. Start by calling the `ggplot` function.  \n2. Use `geom_path` to create continuous lines.  \n3. Time on x-axis.  \n4. Longitudinal position (feet) on y-axis.  \n5. Colour by vehicle speed.  \n6. Create a separate line for each vehicle by specifying `group` as `Vehicle_ID`.  7. Make the lines 50% transparent.  \n8. Use red and green color scale.  \n9. Create small but connected plots (small multiples) for each lane.  \n10. Add labels to axes and colour legend.  \n11. Use the minimal theme to declutter the plot.  \n\n\n![](time_space_diagram.png)\n\n`ggplot2` has this handy function `ggsave` to save the plotted image to disk:  \n\n```{r i808}\n#| eval: false\nggsave(time_space_diagram_i80,           # <1>\n       path = \"time_space_diagram.png\",  # <2>\n       width = 11,                       # <3>\n       height = 8,                       # <4>\n       units = \"in\",                     # <5>\n       dpi = 30)                        # <6>\n```\n1. Specify the plot that you want to save.  \n2. Provide the full path with file name where you want to save the plotted image.  \n3. Specify the width of plotted image.  \n4. Specify the height of plotted image.  \n5. Specify the units of width and height. `\"in\"` means inches.  \n6. Specify the resolution of the image. Higher resolution makes crisper images but takes longer to plot than lower resolution.  \n\nAnd we are done!  Believe it or not, saving this plot took longer than any other step in this post."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"import.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"united","title-block-banner":true,"license":"CC BY","toc-title":"Table of contents","toc-location":"left","author":[{"name":"Umair Durrani","url":"https://umairdurrani.com/"}],"citation":true,"title":"Import Data with R","date":"2024-01-01","categories":["import","time-space"],"image":"trajectories.gif","code-annotations":"hover"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}